
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="An embodied AI agent for Reachy Mini robot powered by Claude Agent SDK">
      
      
      
        <link rel="canonical" href="https://jawhnycooke.github.io/claude-in-the-shell/architecture/voice-pipeline/">
      
      
        <link rel="prev" href="../overview/">
      
      
        <link rel="next" href="../personas/">
      
      
        
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.7.1">
    
    
      
        <title>Voice Pipeline - Reachy Agent Documentation</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.484c7ddc.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.ab4e12ef.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../assets/_mkdocstrings.css">
    
      <link rel="stylesheet" href="../../stylesheets/extra.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="deep-purple" data-md-color-accent="purple">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#understanding-the-voice-pipeline-architecture" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="Reachy Agent Documentation" class="md-header__button md-logo" aria-label="Reachy Agent Documentation" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Reachy Agent Documentation
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Voice Pipeline
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="deep-purple" data-md-color-accent="purple"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="deep-purple" data-md-color-accent="purple"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="https://github.com/jawhnycooke/claude-in-the-shell" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    jawhnycooke/claude-in-the-shell
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../.." class="md-tabs__link">
        
  
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../tutorials/getting-started/" class="md-tabs__link">
          
  
  
  Getting Started

        </a>
      </li>
    
  

      
        
  
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../overview/" class="md-tabs__link">
          
  
  
  Architecture

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../api/agent/" class="md-tabs__link">
          
  
  
  API Reference

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../guides/voice-pipeline-setup/" class="md-tabs__link">
          
  
  
  Guides

        </a>
      </li>
    
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="Reachy Agent Documentation" class="md-nav__button md-logo" aria-label="Reachy Agent Documentation" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    Reachy Agent Documentation
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/jawhnycooke/claude-in-the-shell" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    jawhnycooke/claude-in-the-shell
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Home
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Getting Started
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            
  
    Getting Started
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tutorials/getting-started/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Tutorial
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../guides/troubleshooting/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Troubleshooting
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
      
        
        
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" checked>
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    
  
    Architecture
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            
  
    Architecture
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../overview/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Overview
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    
  
    Voice Pipeline
  

    
  </span>
  
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    
  
    Voice Pipeline
  

    
  </span>
  
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#the-big-picture" class="md-nav__link">
    <span class="md-ellipsis">
      
        The Big Picture
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="The Big Picture">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#why-this-matters" class="md-nav__link">
    <span class="md-ellipsis">
      
        Why This Matters
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#historical-context" class="md-nav__link">
    <span class="md-ellipsis">
      
        Historical Context
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Historical Context">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#the-problem-space" class="md-nav__link">
    <span class="md-ellipsis">
      
        The Problem Space
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#evolution-of-solutions" class="md-nav__link">
    <span class="md-ellipsis">
      
        Evolution of Solutions
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#current-state" class="md-nav__link">
    <span class="md-ellipsis">
      
        Current State
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#core-concepts" class="md-nav__link">
    <span class="md-ellipsis">
      
        Core Concepts
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Core Concepts">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#state-machine-as-the-central-coordinator" class="md-nav__link">
    <span class="md-ellipsis">
      
        State Machine as the Central Coordinator
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#manual-vad-mode-with-openai-realtime" class="md-nav__link">
    <span class="md-ellipsis">
      
        Manual VAD Mode with OpenAI Realtime
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#audio-stream-resampling-16khz-24khz" class="md-nav__link">
    <span class="md-ellipsis">
      
        Audio Stream Resampling (16kHz ↔ 24kHz)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#alsa-shared-device-architecture" class="md-nav__link">
    <span class="md-ellipsis">
      
        ALSA Shared Device Architecture
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#persona-system-with-deferred-switching" class="md-nav__link">
    <span class="md-ellipsis">
      
        Persona System with Deferred Switching
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#architectural-design" class="md-nav__link">
    <span class="md-ellipsis">
      
        Architectural Design
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Architectural Design">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#design-principles" class="md-nav__link">
    <span class="md-ellipsis">
      
        Design Principles
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#key-design-decisions" class="md-nav__link">
    <span class="md-ellipsis">
      
        Key Design Decisions
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Key Design Decisions">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#decision-use-openai-realtime-with-manual-vad-not-server-vad" class="md-nav__link">
    <span class="md-ellipsis">
      
        Decision: Use OpenAI Realtime with Manual VAD (not Server VAD)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#decision-state-machine-with-timeout-guards-not-event-driven-callbacks" class="md-nav__link">
    <span class="md-ellipsis">
      
        Decision: State Machine with Timeout Guards (not Event-Driven Callbacks)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#decision-deferred-persona-switching-not-immediate" class="md-nav__link">
    <span class="md-ellipsis">
      
        Decision: Deferred Persona Switching (not Immediate)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#decision-alsa-shared-devices-not-exclusive-access" class="md-nav__link">
    <span class="md-ellipsis">
      
        Decision: ALSA Shared Devices (not Exclusive Access)
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#data-flow" class="md-nav__link">
    <span class="md-ellipsis">
      
        Data Flow
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Data Flow">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#key-dataflow-insights" class="md-nav__link">
    <span class="md-ellipsis">
      
        Key Dataflow Insights
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#integration-points" class="md-nav__link">
    <span class="md-ellipsis">
      
        Integration Points
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Integration Points">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#agent-integration-process_input-for-claude-responses" class="md-nav__link">
    <span class="md-ellipsis">
      
        Agent Integration: process_input() for Claude Responses
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#motion-integration-headwobble-during-tts" class="md-nav__link">
    <span class="md-ellipsis">
      
        Motion Integration: HeadWobble During TTS
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#motion-integration-idle-behavior-pauseresume" class="md-nav__link">
    <span class="md-ellipsis">
      
        Motion Integration: Idle Behavior Pause/Resume
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#persona-integration-deferred-switching-after-tts" class="md-nav__link">
    <span class="md-ellipsis">
      
        Persona Integration: Deferred Switching After TTS
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#error-handling-recovery" class="md-nav__link">
    <span class="md-ellipsis">
      
        Error Handling &amp; Recovery
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Error Handling &amp; Recovery">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tier-1-retry-with-exponential-backoff" class="md-nav__link">
    <span class="md-ellipsis">
      
        Tier 1: Retry with Exponential Backoff
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tier-2-degraded-mode-operation" class="md-nav__link">
    <span class="md-ellipsis">
      
        Tier 2: Degraded Mode Operation
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tier-3-abort-and-notify" class="md-nav__link">
    <span class="md-ellipsis">
      
        Tier 3: Abort and Notify
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#timeout-guards-preventing-stuck-states" class="md-nav__link">
    <span class="md-ellipsis">
      
        Timeout Guards: Preventing Stuck States
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#health-monitoring-stream-disconnection-detection" class="md-nav__link">
    <span class="md-ellipsis">
      
        Health Monitoring: Stream Disconnection Detection
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#configuration-reference" class="md-nav__link">
    <span class="md-ellipsis">
      
        Configuration Reference
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Configuration Reference">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#top-level-settings" class="md-nav__link">
    <span class="md-ellipsis">
      
        Top-Level Settings
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#personas-multi-wake-word" class="md-nav__link">
    <span class="md-ellipsis">
      
        Personas (Multi-Wake Word)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#wake-word-detection" class="md-nav__link">
    <span class="md-ellipsis">
      
        Wake Word Detection
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#voice-activity-detection-vad" class="md-nav__link">
    <span class="md-ellipsis">
      
        Voice Activity Detection (VAD)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#openai-realtime-api" class="md-nav__link">
    <span class="md-ellipsis">
      
        OpenAI Realtime API
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#audio-hardware" class="md-nav__link">
    <span class="md-ellipsis">
      
        Audio Hardware
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#degraded-mode" class="md-nav__link">
    <span class="md-ellipsis">
      
        Degraded Mode
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#common-misconceptions" class="md-nav__link">
    <span class="md-ellipsis">
      
        Common Misconceptions
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Common Misconceptions">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#misconception-openai-realtime-is-just-stt-tts" class="md-nav__link">
    <span class="md-ellipsis">
      
        Misconception: OpenAI Realtime is just STT + TTS
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#misconception-vad-only-detects-speech-vs-silence" class="md-nav__link">
    <span class="md-ellipsis">
      
        Misconception: VAD only detects "speech vs. silence"
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#misconception-persona-switching-changes-the-ai-model" class="md-nav__link">
    <span class="md-ellipsis">
      
        Misconception: Persona switching changes the AI model
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#misconception-state-timeouts-are-error-conditions" class="md-nav__link">
    <span class="md-ellipsis">
      
        Misconception: State timeouts are error conditions
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#implications-for-practice" class="md-nav__link">
    <span class="md-ellipsis">
      
        Implications for Practice
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Implications for Practice">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#when-working-with-the-voice-pipeline" class="md-nav__link">
    <span class="md-ellipsis">
      
        When Working with the Voice Pipeline
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#design-patterns-that-emerge" class="md-nav__link">
    <span class="md-ellipsis">
      
        Design Patterns That Emerge
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#connecting-to-broader-concepts" class="md-nav__link">
    <span class="md-ellipsis">
      
        Connecting to Broader Concepts
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Connecting to Broader Concepts">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#relationship-to-the-agent-sdk" class="md-nav__link">
    <span class="md-ellipsis">
      
        Relationship to the Agent SDK
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#industry-patterns-real-time-streaming-ai" class="md-nav__link">
    <span class="md-ellipsis">
      
        Industry Patterns: Real-Time Streaming AI
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#future-directions" class="md-nav__link">
    <span class="md-ellipsis">
      
        Future Directions
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#deep-dive-topics" class="md-nav__link">
    <span class="md-ellipsis">
      
        Deep Dive Topics
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#summary-the-mental-model" class="md-nav__link">
    <span class="md-ellipsis">
      
        Summary: The Mental Model
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#further-exploration" class="md-nav__link">
    <span class="md-ellipsis">
      
        Further Exploration
      
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../personas/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Persona System
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../agent-loop/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    ReachyAgentLoop Deep Dive
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../daemon-compatibility/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Daemon Compatibility
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../diagrams/README.md" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Diagrams
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_4" >
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    API Reference
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            
  
    API Reference
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../api/agent/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Agent
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../api/voice-pipeline/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Voice Pipeline
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../api/sdk-motion-control/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    SDK Motion Control
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../api/configuration/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Configuration
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../api/mcp-servers/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    MCP Servers
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../api/motion-blending/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Motion Blending
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../api/permissions/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Permissions
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../api/memory/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Memory
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../api/simulation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Simulation
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../api/mcp-tools/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    MCP Tools
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_5" >
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Guides
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            
  
    Guides
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../guides/voice-pipeline-setup/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Voice Pipeline Setup
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../guides/raspberry-pi-installation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Raspberry Pi Installation
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../guides/phase2-preparation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Phase 2 Preparation
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#the-big-picture" class="md-nav__link">
    <span class="md-ellipsis">
      
        The Big Picture
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="The Big Picture">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#why-this-matters" class="md-nav__link">
    <span class="md-ellipsis">
      
        Why This Matters
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#historical-context" class="md-nav__link">
    <span class="md-ellipsis">
      
        Historical Context
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Historical Context">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#the-problem-space" class="md-nav__link">
    <span class="md-ellipsis">
      
        The Problem Space
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#evolution-of-solutions" class="md-nav__link">
    <span class="md-ellipsis">
      
        Evolution of Solutions
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#current-state" class="md-nav__link">
    <span class="md-ellipsis">
      
        Current State
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#core-concepts" class="md-nav__link">
    <span class="md-ellipsis">
      
        Core Concepts
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Core Concepts">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#state-machine-as-the-central-coordinator" class="md-nav__link">
    <span class="md-ellipsis">
      
        State Machine as the Central Coordinator
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#manual-vad-mode-with-openai-realtime" class="md-nav__link">
    <span class="md-ellipsis">
      
        Manual VAD Mode with OpenAI Realtime
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#audio-stream-resampling-16khz-24khz" class="md-nav__link">
    <span class="md-ellipsis">
      
        Audio Stream Resampling (16kHz ↔ 24kHz)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#alsa-shared-device-architecture" class="md-nav__link">
    <span class="md-ellipsis">
      
        ALSA Shared Device Architecture
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#persona-system-with-deferred-switching" class="md-nav__link">
    <span class="md-ellipsis">
      
        Persona System with Deferred Switching
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#architectural-design" class="md-nav__link">
    <span class="md-ellipsis">
      
        Architectural Design
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Architectural Design">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#design-principles" class="md-nav__link">
    <span class="md-ellipsis">
      
        Design Principles
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#key-design-decisions" class="md-nav__link">
    <span class="md-ellipsis">
      
        Key Design Decisions
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Key Design Decisions">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#decision-use-openai-realtime-with-manual-vad-not-server-vad" class="md-nav__link">
    <span class="md-ellipsis">
      
        Decision: Use OpenAI Realtime with Manual VAD (not Server VAD)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#decision-state-machine-with-timeout-guards-not-event-driven-callbacks" class="md-nav__link">
    <span class="md-ellipsis">
      
        Decision: State Machine with Timeout Guards (not Event-Driven Callbacks)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#decision-deferred-persona-switching-not-immediate" class="md-nav__link">
    <span class="md-ellipsis">
      
        Decision: Deferred Persona Switching (not Immediate)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#decision-alsa-shared-devices-not-exclusive-access" class="md-nav__link">
    <span class="md-ellipsis">
      
        Decision: ALSA Shared Devices (not Exclusive Access)
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#data-flow" class="md-nav__link">
    <span class="md-ellipsis">
      
        Data Flow
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Data Flow">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#key-dataflow-insights" class="md-nav__link">
    <span class="md-ellipsis">
      
        Key Dataflow Insights
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#integration-points" class="md-nav__link">
    <span class="md-ellipsis">
      
        Integration Points
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Integration Points">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#agent-integration-process_input-for-claude-responses" class="md-nav__link">
    <span class="md-ellipsis">
      
        Agent Integration: process_input() for Claude Responses
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#motion-integration-headwobble-during-tts" class="md-nav__link">
    <span class="md-ellipsis">
      
        Motion Integration: HeadWobble During TTS
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#motion-integration-idle-behavior-pauseresume" class="md-nav__link">
    <span class="md-ellipsis">
      
        Motion Integration: Idle Behavior Pause/Resume
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#persona-integration-deferred-switching-after-tts" class="md-nav__link">
    <span class="md-ellipsis">
      
        Persona Integration: Deferred Switching After TTS
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#error-handling-recovery" class="md-nav__link">
    <span class="md-ellipsis">
      
        Error Handling &amp; Recovery
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Error Handling &amp; Recovery">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tier-1-retry-with-exponential-backoff" class="md-nav__link">
    <span class="md-ellipsis">
      
        Tier 1: Retry with Exponential Backoff
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tier-2-degraded-mode-operation" class="md-nav__link">
    <span class="md-ellipsis">
      
        Tier 2: Degraded Mode Operation
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tier-3-abort-and-notify" class="md-nav__link">
    <span class="md-ellipsis">
      
        Tier 3: Abort and Notify
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#timeout-guards-preventing-stuck-states" class="md-nav__link">
    <span class="md-ellipsis">
      
        Timeout Guards: Preventing Stuck States
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#health-monitoring-stream-disconnection-detection" class="md-nav__link">
    <span class="md-ellipsis">
      
        Health Monitoring: Stream Disconnection Detection
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#configuration-reference" class="md-nav__link">
    <span class="md-ellipsis">
      
        Configuration Reference
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Configuration Reference">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#top-level-settings" class="md-nav__link">
    <span class="md-ellipsis">
      
        Top-Level Settings
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#personas-multi-wake-word" class="md-nav__link">
    <span class="md-ellipsis">
      
        Personas (Multi-Wake Word)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#wake-word-detection" class="md-nav__link">
    <span class="md-ellipsis">
      
        Wake Word Detection
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#voice-activity-detection-vad" class="md-nav__link">
    <span class="md-ellipsis">
      
        Voice Activity Detection (VAD)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#openai-realtime-api" class="md-nav__link">
    <span class="md-ellipsis">
      
        OpenAI Realtime API
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#audio-hardware" class="md-nav__link">
    <span class="md-ellipsis">
      
        Audio Hardware
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#degraded-mode" class="md-nav__link">
    <span class="md-ellipsis">
      
        Degraded Mode
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#common-misconceptions" class="md-nav__link">
    <span class="md-ellipsis">
      
        Common Misconceptions
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Common Misconceptions">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#misconception-openai-realtime-is-just-stt-tts" class="md-nav__link">
    <span class="md-ellipsis">
      
        Misconception: OpenAI Realtime is just STT + TTS
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#misconception-vad-only-detects-speech-vs-silence" class="md-nav__link">
    <span class="md-ellipsis">
      
        Misconception: VAD only detects "speech vs. silence"
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#misconception-persona-switching-changes-the-ai-model" class="md-nav__link">
    <span class="md-ellipsis">
      
        Misconception: Persona switching changes the AI model
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#misconception-state-timeouts-are-error-conditions" class="md-nav__link">
    <span class="md-ellipsis">
      
        Misconception: State timeouts are error conditions
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#implications-for-practice" class="md-nav__link">
    <span class="md-ellipsis">
      
        Implications for Practice
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Implications for Practice">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#when-working-with-the-voice-pipeline" class="md-nav__link">
    <span class="md-ellipsis">
      
        When Working with the Voice Pipeline
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#design-patterns-that-emerge" class="md-nav__link">
    <span class="md-ellipsis">
      
        Design Patterns That Emerge
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#connecting-to-broader-concepts" class="md-nav__link">
    <span class="md-ellipsis">
      
        Connecting to Broader Concepts
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Connecting to Broader Concepts">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#relationship-to-the-agent-sdk" class="md-nav__link">
    <span class="md-ellipsis">
      
        Relationship to the Agent SDK
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#industry-patterns-real-time-streaming-ai" class="md-nav__link">
    <span class="md-ellipsis">
      
        Industry Patterns: Real-Time Streaming AI
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#future-directions" class="md-nav__link">
    <span class="md-ellipsis">
      
        Future Directions
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#deep-dive-topics" class="md-nav__link">
    <span class="md-ellipsis">
      
        Deep Dive Topics
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#summary-the-mental-model" class="md-nav__link">
    <span class="md-ellipsis">
      
        Summary: The Mental Model
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#further-exploration" class="md-nav__link">
    <span class="md-ellipsis">
      
        Further Exploration
      
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              
              <article class="md-content__inner md-typeset">
                
                  


  
  


<h1 id="understanding-the-voice-pipeline-architecture">Understanding the Voice Pipeline Architecture<a class="headerlink" href="#understanding-the-voice-pipeline-architecture" title="Permanent link">&para;</a></h1>
<blockquote>
<p><strong>Purpose</strong>: This document explains the architectural design and component interactions of Reachy's voice interaction system
<strong>Audience</strong>: Developers working on voice features, integration engineers, and system architects
<strong>Prerequisite Knowledge</strong>: Familiarity with async Python, state machines, audio processing concepts</p>
</blockquote>
<h2 id="the-big-picture">The Big Picture<a class="headerlink" href="#the-big-picture" title="Permanent link">&para;</a></h2>
<p>The Voice Pipeline transforms Reachy from a manually-controlled robot into an autonomous conversational agent. It orchestrates a complex real-time dataflow from wake word detection through speech recognition, AI processing, and synthesized speech output—all while maintaining tight integration with Reachy's physical embodiment through synchronized head movements and idle behaviors.</p>
<h3 id="why-this-matters">Why This Matters<a class="headerlink" href="#why-this-matters" title="Permanent link">&para;</a></h3>
<p>Voice interaction is the primary interface for autonomous operation. Unlike traditional chatbots that process discrete text messages, the Voice Pipeline must:</p>
<ul>
<li><strong>Maintain conversational context</strong> across multiple turns</li>
<li><strong>Coordinate with physical embodiment</strong> (head wobble during speech, idle behaviors)</li>
<li><strong>Handle real-time constraints</strong> (low latency, no dropped audio frames)</li>
<li><strong>Degrade gracefully</strong> when components fail (network outages, hardware issues)</li>
<li><strong>Support multiple personas</strong> with distinct voices and personalities</li>
</ul>
<p>The architecture's resilience and state management directly determine whether Reachy feels responsive and natural, or sluggish and robotic.</p>
<h2 id="historical-context">Historical Context<a class="headerlink" href="#historical-context" title="Permanent link">&para;</a></h2>
<h3 id="the-problem-space">The Problem Space<a class="headerlink" href="#the-problem-space" title="Permanent link">&para;</a></h3>
<p>Desktop robots face unique challenges for voice interaction:</p>
<ol>
<li><strong>Limited computational resources</strong> - Raspberry Pi 4 cannot run full STT/TTS models locally</li>
<li><strong>Shared audio hardware</strong> - Daemon (motion SDK) and voice pipeline both need microphone/speaker access</li>
<li><strong>Network dependency</strong> - Cloud APIs introduce latency and failure modes</li>
<li><strong>Physical embodiment constraints</strong> - Voice must synchronize with motor control (wobble, breathing)</li>
<li><strong>Wake word false positives</strong> - Room noise, TV audio, Reachy's own voice can trigger detection</li>
</ol>
<h3 id="evolution-of-solutions">Evolution of Solutions<a class="headerlink" href="#evolution-of-solutions" title="Permanent link">&para;</a></h3>
<p><strong>First Generation (HTTP Polling)</strong>:
- Simple HTTP requests to OpenAI API
- No wake word detection (always listening or manual trigger)
- Blocking I/O caused motion freezes
- No error recovery or degraded modes</p>
<p><strong>Second Generation (Event-Driven)</strong>:
- Added OpenWakeWord for wake word detection
- Async I/O separated from motion control
- Basic retry logic for API failures
- Still brittle—single component failure stopped entire pipeline</p>
<p><strong>Current Architecture (State Machine + Recovery)</strong>:
- Explicit state machine with validated transitions
- Timeout guards prevent stuck states
- Multi-level recovery strategies (retry → degrade → abort)
- OpenAI Realtime API for streaming STT/TTS
- Persona system for multi-personality support
- HeadWobble synchronized with TTS audio amplitude</p>
<h3 id="current-state">Current State<a class="headerlink" href="#current-state" title="Permanent link">&para;</a></h3>
<p>The Voice Pipeline is production-ready with comprehensive error handling, but still evolving:</p>
<ul>
<li><strong>Stable</strong>: State machine, audio management, wake word detection</li>
<li><strong>Maturing</strong>: OpenAI Realtime integration (manual VAD mode), persona switching</li>
<li><strong>Experimental</strong>: Multi-persona wake words (Ghost in the Shell theme), local TTS fallback</li>
</ul>
<h2 id="core-concepts">Core Concepts<a class="headerlink" href="#core-concepts" title="Permanent link">&para;</a></h2>
<h3 id="state-machine-as-the-central-coordinator">State Machine as the Central Coordinator<a class="headerlink" href="#state-machine-as-the-central-coordinator" title="Permanent link">&para;</a></h3>
<p><strong>What it is</strong>: A finite state machine (FSM) that models the voice interaction lifecycle as discrete states with validated transitions.</p>
<p><strong>Why it exists</strong>: Real-time audio processing involves complex asynchronous operations (WebSocket connections, audio buffering, motor control). Without explicit state management, race conditions and deadlocks are inevitable. The FSM provides:
- <strong>Predictability</strong>: Only valid transitions are allowed (e.g., cannot jump from WAKE_DETECTED to SPEAKING)
- <strong>Debuggability</strong>: Every state transition is logged with timestamps
- <strong>Timeout safety</strong>: States that should be transient (PROCESSING) have timeout guards</p>
<p><strong>How it relates</strong>: The state machine is the "brain" that coordinates all other components (AudioManager, WakeWordDetector, OpenAI client, Agent).</p>
<pre class="mermaid"><code>stateDiagram-v2
    [*] --&gt; IDLE
    IDLE --&gt; LISTENING_WAKE: start()

    LISTENING_WAKE --&gt; WAKE_DETECTED: wake word detected
    LISTENING_WAKE --&gt; LISTENING_SPEECH: degraded mode (no wake word)
    LISTENING_WAKE --&gt; IDLE: stop()
    LISTENING_WAKE --&gt; ERROR: component failure

    WAKE_DETECTED --&gt; LISTENING_SPEECH: ready to listen
    WAKE_DETECTED --&gt; LISTENING_WAKE: timeout (2s)
    WAKE_DETECTED --&gt; ERROR: component failure

    LISTENING_SPEECH --&gt; PROCESSING: end-of-speech detected
    LISTENING_SPEECH --&gt; LISTENING_WAKE: empty/invalid speech
    LISTENING_SPEECH --&gt; IDLE: stop()
    LISTENING_SPEECH --&gt; ERROR: timeout (35s) or failure

    PROCESSING --&gt; SPEAKING: response received
    PROCESSING --&gt; LISTENING_WAKE: empty response
    PROCESSING --&gt; IDLE: stop()
    PROCESSING --&gt; ERROR: timeout (90s) or agent failure

    SPEAKING --&gt; LISTENING_WAKE: playback complete
    SPEAKING --&gt; IDLE: stop()
    SPEAKING --&gt; ERROR: timeout (180s) or audio failure

    ERROR --&gt; LISTENING_WAKE: recovery successful
    ERROR --&gt; IDLE: recovery failed or max retries
    ERROR --&gt; ERROR: retry delay

    note right of LISTENING_SPEECH
        Timeout: 35s (max speech + buffer)
        Guards against infinite recording
    end note

    note right of PROCESSING
        Timeout: 90s (includes tool calls)
        Claude can invoke multiple MCP tools
    end note

    note right of SPEAKING
        Timeout: 180s (3 minutes max)
        Long philosophical responses
    end note</code></pre>
<p><strong>Mental Model</strong>: Think of the state machine like a traffic light controller—it enforces safe transitions between states, prevents illegal moves (e.g., going from red directly to green without yellow), and has fallback logic (flashing red) when sensors fail.</p>
<h3 id="manual-vad-mode-with-openai-realtime">Manual VAD Mode with OpenAI Realtime<a class="headerlink" href="#manual-vad-mode-with-openai-realtime" title="Permanent link">&para;</a></h3>
<p><strong>What it is</strong>: A configuration where the local Silero VAD (Voice Activity Detector) determines end-of-speech, then commits the buffered audio to OpenAI Realtime for transcription.</p>
<p><strong>Why it exists</strong>: OpenAI Realtime has two modes:
1. <strong>Server VAD</strong> - Server decides when speech ends (lower latency, less control)
2. <strong>Manual VAD</strong> - Client controls speech segmentation (more control, requires local VAD)</p>
<p>We use manual VAD because:
- <strong>Persona switching requires local control</strong> - We need to know which wake word was detected before sending to OpenAI
- <strong>Multi-turn conversations need explicit boundaries</strong> - Server VAD can merge separate questions
- <strong>Silero VAD works offline</strong> - Provides fallback when network is flaky</p>
<p><strong>How it relates</strong>: The VoicePipeline buffers audio chunks during LISTENING_SPEECH state. When VAD detects end-of-speech, the pipeline commits the entire buffer to OpenAI via <code>commit_audio_buffer()</code>.</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="c1"># Key interface in openai_realtime.py</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a><span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">commit_audio_buffer</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">list</span><span class="p">[</span><span class="nb">bytes</span><span class="p">]]:</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Finalize audio input and wait for transcription + TTS.</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a><span class="sd">    Returns:</span>
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a><span class="sd">        (transcript, audio_chunks) - The recognized text and TTS audio</span>
</span><span id="__span-0-7"><a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a><span class="sd">    &quot;&quot;&quot;</span>
</span></code></pre></div>
<p><strong>Trade-offs</strong>:
- <strong>Pro</strong>: Full control over conversation turn boundaries
- <strong>Pro</strong>: Can switch voices/personas mid-conversation
- <strong>Con</strong>: Additional latency (local VAD processing + network roundtrip)
- <strong>Con</strong>: More complex state management (buffering, committing, clearing)</p>
<h3 id="audio-stream-resampling-16khz-24khz">Audio Stream Resampling (16kHz ↔ 24kHz)<a class="headerlink" href="#audio-stream-resampling-16khz-24khz" title="Permanent link">&para;</a></h3>
<p><strong>What it is</strong>: Real-time conversion between Reachy's microphone sample rate (16kHz) and OpenAI Realtime's expected rate (24kHz), and vice versa for speaker output.</p>
<p><strong>Why it exists</strong>:
- <strong>Silero VAD requires 16kHz</strong> - The model is trained on 16kHz audio with 512-sample chunks
- <strong>OpenAI Realtime uses 24kHz</strong> - Higher quality for STT/TTS
- <strong>Reachy's hardware native rate is 16kHz</strong> - Less CPU overhead on Pi</p>
<p><strong>How it relates</strong>: The <code>AudioManager</code> performs resampling transparently:</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-1-1"><a id="__codelineno-1-1" name="__codelineno-1-1" href="#__codelineno-1-1"></a><span class="c1"># AudioManager interface</span>
</span><span id="__span-1-2"><a id="__codelineno-1-2" name="__codelineno-1-2" href="#__codelineno-1-2"></a><span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">read_chunk</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bytes</span><span class="p">:</span>
</span><span id="__span-1-3"><a id="__codelineno-1-3" name="__codelineno-1-3" href="#__codelineno-1-3"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Read one 512-sample chunk at 16kHz (for VAD).&quot;&quot;&quot;</span>
</span><span id="__span-1-4"><a id="__codelineno-1-4" name="__codelineno-1-4" href="#__codelineno-1-4"></a>
</span><span id="__span-1-5"><a id="__codelineno-1-5" name="__codelineno-1-5" href="#__codelineno-1-5"></a><span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">send_audio_to_openai</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">chunk_16khz</span><span class="p">:</span> <span class="nb">bytes</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bytes</span><span class="p">:</span>
</span><span id="__span-1-6"><a id="__codelineno-1-6" name="__codelineno-1-6" href="#__codelineno-1-6"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Resample 16kHz → 24kHz for OpenAI.&quot;&quot;&quot;</span>
</span></code></pre></div>
<p><strong>Mental Model</strong>: Think of it like video format conversion—the content is the same, but the resolution changes to match each component's requirements.</p>
<h3 id="alsa-shared-device-architecture">ALSA Shared Device Architecture<a class="headerlink" href="#alsa-shared-device-architecture" title="Permanent link">&para;</a></h3>
<p><strong>What it is</strong>: ALSA (Advanced Linux Sound Architecture) virtual devices that allow multiple processes to access the same hardware concurrently.</p>
<p><strong>Why it exists</strong>: Both the Reachy daemon (for SDK <code>play_audio()</code> calls) and the Voice Pipeline need microphone/speaker access simultaneously. Linux audio devices are typically exclusive-access.</p>
<p><strong>Solution</strong>:
- <strong>dsnoop</strong> (device 4) - Shared input from 4-mic array
- <strong>dmix</strong> (device 3) - Mixed output to speaker</p>
<div class="language-yaml highlight"><pre><span></span><code><span id="__span-2-1"><a id="__codelineno-2-1" name="__codelineno-2-1" href="#__codelineno-2-1"></a><span class="c1"># config/default.yaml</span>
</span><span id="__span-2-2"><a id="__codelineno-2-2" name="__codelineno-2-2" href="#__codelineno-2-2"></a><span class="nt">audio</span><span class="p">:</span>
</span><span id="__span-2-3"><a id="__codelineno-2-3" name="__codelineno-2-3" href="#__codelineno-2-3"></a><span class="w">  </span><span class="nt">input_device_index</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">4</span><span class="w">   </span><span class="c1"># reachymini_audio_src (dsnoop)</span>
</span><span id="__span-2-4"><a id="__codelineno-2-4" name="__codelineno-2-4" href="#__codelineno-2-4"></a><span class="w">  </span><span class="nt">output_device_index</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">3</span><span class="w">  </span><span class="c1"># reachymini_audio_sink (dmix)</span>
</span></code></pre></div>
<p><strong>Trade-offs</strong>:
- <strong>Pro</strong>: No resource conflicts between daemon and voice pipeline
- <strong>Con</strong>: Slight latency increase (dmix buffering)
- <strong>Con</strong>: Platform-specific configuration (ALSA on Raspberry Pi OS)</p>
<h3 id="persona-system-with-deferred-switching">Persona System with Deferred Switching<a class="headerlink" href="#persona-system-with-deferred-switching" title="Permanent link">&para;</a></h3>
<p><strong>What it is</strong>: Multiple AI personalities (e.g., "Motoko", "Batou") with distinct wake words, voices, and system prompts. Persona switches are deferred until after TTS playback completes.</p>
<p><strong>Why it exists</strong>:
- <strong>Ghost in the Shell theme</strong> - Each persona has unique characteristics (analytical vs. action-oriented)
- <strong>Context preservation</strong> - Switching mid-conversation would lose conversational context
- <strong>Voice consistency</strong> - TTS audio must match the persona who started speaking</p>
<p><strong>How it works</strong>:</p>
<ol>
<li>User says "Hey Motoko" → Wake word detector identifies model <code>hey_motoko</code></li>
<li>Pipeline marks <code>_pending_persona_switch = PersonaConfig("motoko", voice="nova", ...)</code></li>
<li>Current response completes with current persona's voice</li>
<li>After TTS playback, pipeline applies switch and updates OpenAI voice</li>
</ol>
<div class="language-python highlight"><pre><span></span><code><span id="__span-3-1"><a id="__codelineno-3-1" name="__codelineno-3-1" href="#__codelineno-3-1"></a><span class="c1"># Deferred switching in pipeline.py</span>
</span><span id="__span-3-2"><a id="__codelineno-3-2" name="__codelineno-3-2" href="#__codelineno-3-2"></a><span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">_play_response</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-3-3"><a id="__codelineno-3-3" name="__codelineno-3-3" href="#__codelineno-3-3"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Play TTS response, then apply pending persona switch.&quot;&quot;&quot;</span>
</span><span id="__span-3-4"><a id="__codelineno-3-4" name="__codelineno-3-4" href="#__codelineno-3-4"></a>    <span class="c1"># ... play audio ...</span>
</span><span id="__span-3-5"><a id="__codelineno-3-5" name="__codelineno-3-5" href="#__codelineno-3-5"></a>
</span><span id="__span-3-6"><a id="__codelineno-3-6" name="__codelineno-3-6" href="#__codelineno-3-6"></a>    <span class="c1"># Apply deferred persona switch after response completes</span>
</span><span id="__span-3-7"><a id="__codelineno-3-7" name="__codelineno-3-7" href="#__codelineno-3-7"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_pending_persona_switch</span><span class="p">:</span>
</span><span id="__span-3-8"><a id="__codelineno-3-8" name="__codelineno-3-8" href="#__codelineno-3-8"></a>        <span class="k">await</span> <span class="bp">self</span><span class="o">.</span><span class="n">_apply_persona_switch</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_pending_persona_switch</span><span class="p">)</span>
</span><span id="__span-3-9"><a id="__codelineno-3-9" name="__codelineno-3-9" href="#__codelineno-3-9"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_pending_persona_switch</span> <span class="o">=</span> <span class="kc">None</span>
</span></code></pre></div>
<p><strong>Trade-offs</strong>:
- <strong>Pro</strong>: No mid-conversation voice changes (jarring UX)
- <strong>Pro</strong>: Maintains conversational coherence
- <strong>Con</strong>: One-turn delay before new persona activates
- <strong>Con</strong>: User must wait for current response to finish</p>
<h2 id="architectural-design">Architectural Design<a class="headerlink" href="#architectural-design" title="Permanent link">&para;</a></h2>
<h3 id="design-principles">Design Principles<a class="headerlink" href="#design-principles" title="Permanent link">&para;</a></h3>
<ol>
<li><strong>Fail Gracefully, Never Crash</strong></li>
<li>Rationale: Robot interaction should feel natural—network glitches shouldn't cause abrupt silence</li>
<li>Impact: Extensive error handling in every async operation, recovery strategies at multiple levels</li>
<li>
<p>Trade-offs: More complex code, additional testing burden for degraded modes</p>
</li>
<li>
<p><strong>State is Explicit, Transitions are Validated</strong></p>
</li>
<li>Rationale: Async audio processing creates race conditions; explicit FSM prevents impossible states</li>
<li>Impact: Every state change goes through <code>_set_state()</code> with transition validation</li>
<li>
<p>Trade-offs: Less flexibility (cannot bypass state machine), more verbose logging</p>
</li>
<li>
<p><strong>Local Components are Fallbacks, Not Replacements</strong></p>
</li>
<li>Rationale: Cloud APIs provide better quality, but we need offline capability for demos/development</li>
<li>Impact: OpenWakeWord models can fall back to bundled models, Silero VAD falls back to energy-based detection</li>
<li>
<p>Trade-offs: Larger binary size (bundled models), more configuration options</p>
</li>
<li>
<p><strong>Physical Embodiment is First-Class</strong></p>
</li>
<li>Rationale: Voice without synchronized motion feels disconnected and robotic</li>
<li>Impact: HeadWobble receives real-time audio amplitude, idle behaviors pause during conversation</li>
<li>Trade-offs: Motion control failures can block voice pipeline (mitigated by error handling)</li>
</ol>
<h3 id="key-design-decisions">Key Design Decisions<a class="headerlink" href="#key-design-decisions" title="Permanent link">&para;</a></h3>
<h4 id="decision-use-openai-realtime-with-manual-vad-not-server-vad">Decision: Use OpenAI Realtime with Manual VAD (not Server VAD)<a class="headerlink" href="#decision-use-openai-realtime-with-manual-vad-not-server-vad" title="Permanent link">&para;</a></h4>
<p><strong>Context</strong>: OpenAI Realtime API offers two modes for detecting end-of-speech:
1. <strong>Server VAD</strong> - OpenAI decides when user finished speaking (simpler, lower latency)
2. <strong>Manual VAD</strong> - Client sends explicit "commit" signal (more control, requires local VAD)</p>
<p><strong>Options Considered</strong>:</p>
<ol>
<li><strong>Server VAD Mode</strong></li>
<li>Pros: Simpler implementation, lower latency (one less processing step), no local VAD needed</li>
<li>
<p>Cons: Cannot switch personas mid-session (voice is session-scoped), less control over turn boundaries, potential for merging separate questions</p>
</li>
<li>
<p><strong>Manual VAD Mode</strong> (chosen)</p>
</li>
<li>Pros: Full control over when audio is committed, can switch OpenAI voice between turns, explicit conversation boundaries</li>
<li>Cons: Requires local Silero VAD (CPU overhead on Pi), additional latency (VAD processing + buffer commit), more complex state management</li>
</ol>
<p><strong>Choice Made</strong>: Manual VAD mode</p>
<p><strong>Rationale</strong>:
- Persona switching is a core feature—requires ability to change OpenAI voice parameter between turns
- Explicit turn boundaries improve conversational quality (server VAD sometimes merges "What time is it? Also, move your head left" into one turn)
- Silero VAD provides offline capability for development/demos without network</p>
<p><strong>Consequences</strong>:
- Voice Pipeline must maintain audio buffer during LISTENING_SPEECH state
- End-of-speech detection is client-side responsibility (more error modes)
- Switching personas mid-conversation requires WebSocket reconnection with new session config</p>
<hr />
<h4 id="decision-state-machine-with-timeout-guards-not-event-driven-callbacks">Decision: State Machine with Timeout Guards (not Event-Driven Callbacks)<a class="headerlink" href="#decision-state-machine-with-timeout-guards-not-event-driven-callbacks" title="Permanent link">&para;</a></h4>
<p><strong>Context</strong>: Real-time voice processing involves many asynchronous operations that can hang (network timeouts, hardware failures). We needed a mechanism to prevent the pipeline from getting stuck.</p>
<p><strong>Options Considered</strong>:</p>
<ol>
<li><strong>Pure Async/Await with Try/Except</strong></li>
<li>Pros: Simple, idiomatic Python, minimal abstraction</li>
<li>
<p>Cons: No global view of pipeline state, hard to detect "stuck" conditions (e.g., waiting for speech that never ends)</p>
</li>
<li>
<p><strong>Event-Driven Callbacks</strong> (Actor Model)</p>
</li>
<li>Pros: Decoupled components, easy to add new event handlers</li>
<li>
<p>Cons: Harder to reason about state, callback hell, difficult to enforce valid transitions</p>
</li>
<li>
<p><strong>Explicit State Machine with Timeout Guards</strong> (chosen)</p>
</li>
<li>Pros: Clear state at any moment, enforced valid transitions, automatic timeout recovery</li>
<li>Cons: More boilerplate (state transition validation), harder to add new states, verbose logging</li>
</ol>
<p><strong>Choice Made</strong>: State machine with timeout guards</p>
<p><strong>Rationale</strong>:
- <strong>Debuggability</strong>: When users report "Reachy stopped listening", logs show exactly which state timed out
- <strong>Safety</strong>: Timeout guards prevent infinite waits (e.g., LISTENING_SPEECH has 35s timeout)
- <strong>Testability</strong>: Can unit test each state transition independently</p>
<p><strong>Consequences</strong>:
- Every new state requires timeout configuration in <code>STATE_TIMEOUTS</code>
- State transition matrix must be updated when adding states (<code>VALID_TRANSITIONS</code>)
- More complex code structure (state transition validation, timeout task management)</p>
<hr />
<h4 id="decision-deferred-persona-switching-not-immediate">Decision: Deferred Persona Switching (not Immediate)<a class="headerlink" href="#decision-deferred-persona-switching-not-immediate" title="Permanent link">&para;</a></h4>
<p><strong>Context</strong>: Wake word detection happens at the start of a conversation turn, but OpenAI Realtime sessions are voice-scoped. Switching voices mid-session requires WebSocket reconnection.</p>
<p><strong>Options Considered</strong>:</p>
<ol>
<li><strong>Immediate Switching on Wake Word</strong></li>
<li>Pros: User sees instant feedback (Reachy "becomes" the new persona)</li>
<li>
<p>Cons: Interrupts current TTS playback (jarring), loses WebSocket connection mid-response, complex reconnection logic</p>
</li>
<li>
<p><strong>One Session Per Turn</strong> (create new session for each question)</p>
</li>
<li>Pros: Clean separation, easy to switch voices</li>
<li>
<p>Cons: Significant latency overhead (WebSocket handshake every turn), loses conversational context</p>
</li>
<li>
<p><strong>Deferred Switching After TTS Completes</strong> (chosen)</p>
</li>
<li>Pros: Smooth UX (no interruptions), maintains conversational flow, simple implementation</li>
<li>Cons: One-turn delay before persona activates, user must wait for current response to finish</li>
</ol>
<p><strong>Choice Made</strong>: Deferred switching after TTS playback</p>
<p><strong>Rationale</strong>:
- <strong>User experience</strong>: Interrupting mid-sentence is jarring and feels buggy
- <strong>Technical simplicity</strong>: Switching between turns avoids complex WebSocket state management
- <strong>Conversational coherence</strong>: Current question gets answered in the voice that started the conversation</p>
<p><strong>Consequences</strong>:
- Pipeline tracks <code>_pending_persona_switch</code> state variable
- Wake word detection must map model name → PersonaConfig
- Persona switches require WebSocket reconnection (brief pause before next turn)</p>
<hr />
<h4 id="decision-alsa-shared-devices-not-exclusive-access">Decision: ALSA Shared Devices (not Exclusive Access)<a class="headerlink" href="#decision-alsa-shared-devices-not-exclusive-access" title="Permanent link">&para;</a></h4>
<p><strong>Context</strong>: Reachy daemon and Voice Pipeline both need audio hardware access. Standard ALSA devices are exclusive-access (one process locks the device).</p>
<p><strong>Options Considered</strong>:</p>
<ol>
<li><strong>PulseAudio Server</strong></li>
<li>Pros: Industry standard, automatic mixing, per-app volume control</li>
<li>
<p>Cons: Additional daemon overhead on Pi 4, configuration complexity, another failure point</p>
</li>
<li>
<p><strong>Exclusive Access with Mutex</strong></p>
</li>
<li>Pros: Simple, no shared device configuration</li>
<li>
<p>Cons: Daemon and voice pipeline cannot run simultaneously (breaks autonomous mode)</p>
</li>
<li>
<p><strong>ALSA dsnoop/dmix Virtual Devices</strong> (chosen)</p>
</li>
<li>Pros: Lightweight (kernel-level), no additional daemons, works with PyAudio</li>
<li>Cons: ALSA-specific (not portable to macOS), requires manual device index configuration</li>
</ol>
<p><strong>Choice Made</strong>: ALSA dsnoop (input) / dmix (output)</p>
<p><strong>Rationale</strong>:
- <strong>Raspberry Pi OS is the target platform</strong> - ALSA portability not critical
- <strong>Minimal overhead</strong> - No PulseAudio daemon competing for CPU
- <strong>Proven solution</strong> - Reachy daemon already uses dmix for SDK audio</p>
<p><strong>Consequences</strong>:
- Device indices are hardcoded in config (device 4 = dsnoop, device 3 = dmix)
- Development on macOS requires mock daemon or different device indices
- ALSA configuration must be validated during setup (see <code>scripts/setup_audio.sh</code>)</p>
<h2 id="data-flow">Data Flow<a class="headerlink" href="#data-flow" title="Permanent link">&para;</a></h2>
<p>The following sequence diagram illustrates a complete conversation turn, from wake word detection through TTS playback:</p>
<pre class="mermaid"><code>sequenceDiagram
    participant User
    participant WakeWord as WakeWordDetector
    participant Audio as AudioManager
    participant VAD as VoiceActivityDetector
    participant Pipeline as VoicePipeline
    participant OpenAI as OpenAIRealtimeClient
    participant Agent as ReachyAgentLoop
    participant Motion as BlendController

    Note over Pipeline: State: LISTENING_WAKE
    Pipeline-&gt;&gt;Audio: start_recording()
    Pipeline-&gt;&gt;WakeWord: start()

    loop Listen for wake word
        Audio-&gt;&gt;WakeWord: process_chunk(audio_16khz)
        WakeWord--&gt;&gt;Pipeline: on_wake("hey_motoko")
    end

    Note over Pipeline: State: WAKE_DETECTED
    Pipeline-&gt;&gt;Motion: pause_idle_behavior()
    Pipeline-&gt;&gt;Pipeline: mark pending persona switch

    Note over Pipeline: State: LISTENING_SPEECH
    Pipeline-&gt;&gt;OpenAI: connect() [manual VAD mode]
    Pipeline-&gt;&gt;VAD: start()

    loop Buffer user speech
        Audio-&gt;&gt;Pipeline: read_chunk() [16kHz]
        Pipeline-&gt;&gt;VAD: process_chunk()
        VAD--&gt;&gt;Pipeline: is_speech=True
        Pipeline-&gt;&gt;Pipeline: buffer_chunk()
        Pipeline-&gt;&gt;OpenAI: send_audio(resampled_24khz)
    end

    VAD--&gt;&gt;Pipeline: on_speech_end(duration=3.5s)
    Note over Pipeline: Silence threshold reached (800ms)

    Note over Pipeline: State: PROCESSING
    Pipeline-&gt;&gt;OpenAI: commit_audio_buffer()
    OpenAI--&gt;&gt;Pipeline: transcript="What time is it?"

    Pipeline-&gt;&gt;Agent: process_input("What time is it?")
    Agent-&gt;&gt;Agent: Run Claude SDK loop
    Agent--&gt;&gt;Pipeline: response="It's 2:30 PM"

    Note over Pipeline: State: SPEAKING
    Pipeline-&gt;&gt;OpenAI: request_tts("It's 2:30 PM", voice="nova")

    loop Stream TTS audio
        OpenAI--&gt;&gt;Pipeline: audio_chunk [24kHz]
        Pipeline-&gt;&gt;Audio: play_chunk(resampled_16khz)
        OpenAI--&gt;&gt;Pipeline: amplitude=0.8
        Pipeline-&gt;&gt;Motion: wobble.update_amplitude(0.8)
    end

    Audio--&gt;&gt;Pipeline: playback_complete()
    Pipeline-&gt;&gt;Pipeline: apply_pending_persona_switch()
    Pipeline-&gt;&gt;OpenAI: reconnect(voice="nova")

    Note over Pipeline: State: LISTENING_WAKE
    Pipeline-&gt;&gt;Motion: resume_idle_behavior()</code></pre>
<h3 id="key-dataflow-insights">Key Dataflow Insights<a class="headerlink" href="#key-dataflow-insights" title="Permanent link">&para;</a></h3>
<ol>
<li><strong>Audio Resampling Happens at Pipeline Boundaries</strong></li>
<li>Microphone → VAD: 16kHz (Silero's native rate)</li>
<li>Pipeline → OpenAI: 24kHz (upsampled via <code>resample_to_24khz()</code>)</li>
<li>
<p>OpenAI → Speaker: 24kHz → 16kHz (downsampled)</p>
</li>
<li>
<p><strong>Buffering Strategy</strong></p>
</li>
<li>During LISTENING_SPEECH: Audio chunks buffered in <code>_audio_buffer</code></li>
<li>On end-of-speech: Entire buffer committed to OpenAI with <code>commit_audio_buffer()</code></li>
<li>
<p>After commit: Buffer cleared, ready for next turn</p>
</li>
<li>
<p><strong>Amplitude-Driven Motion</strong></p>
</li>
<li>OpenAI Realtime emits audio amplitude with each TTS chunk</li>
<li>Pipeline forwards to <code>HeadWobble.update_amplitude()</code></li>
<li>
<p>HeadWobble modulates head pitch/yaw based on amplitude (appears to "speak")</p>
</li>
<li>
<p><strong>Persona Switching Sequence</strong></p>
</li>
<li>Wake word detected → Mark pending switch (don't apply yet)</li>
<li>Current response completes → Apply switch</li>
<li>Reconnect WebSocket with new voice parameter</li>
<li>Next turn uses new persona</li>
</ol>
<h2 id="integration-points">Integration Points<a class="headerlink" href="#integration-points" title="Permanent link">&para;</a></h2>
<h3 id="agent-integration-process_input-for-claude-responses">Agent Integration: <code>process_input()</code> for Claude Responses<a class="headerlink" href="#agent-integration-process_input-for-claude-responses" title="Permanent link">&para;</a></h3>
<p>The Voice Pipeline delegates all conversational AI to the <code>ReachyAgentLoop</code> via the <code>process_input()</code> method:</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-4-1"><a id="__codelineno-4-1" name="__codelineno-4-1" href="#__codelineno-4-1"></a><span class="c1"># In pipeline.py (PROCESSING state)</span>
</span><span id="__span-4-2"><a id="__codelineno-4-2" name="__codelineno-4-2" href="#__codelineno-4-2"></a><span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">_process_speech</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-4-3"><a id="__codelineno-4-3" name="__codelineno-4-3" href="#__codelineno-4-3"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Process transcribed speech through Claude agent.&quot;&quot;&quot;</span>
</span><span id="__span-4-4"><a id="__codelineno-4-4" name="__codelineno-4-4" href="#__codelineno-4-4"></a>
</span><span id="__span-4-5"><a id="__codelineno-4-5" name="__codelineno-4-5" href="#__codelineno-4-5"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">agent</span><span class="p">:</span>
</span><span id="__span-4-6"><a id="__codelineno-4-6" name="__codelineno-4-6" href="#__codelineno-4-6"></a>        <span class="n">response_text</span> <span class="o">=</span> <span class="k">await</span> <span class="bp">self</span><span class="o">.</span><span class="n">agent</span><span class="o">.</span><span class="n">process_input</span><span class="p">(</span>
</span><span id="__span-4-7"><a id="__codelineno-4-7" name="__codelineno-4-7" href="#__codelineno-4-7"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_current_transcript</span><span class="p">,</span>
</span><span id="__span-4-8"><a id="__codelineno-4-8" name="__codelineno-4-8" href="#__codelineno-4-8"></a>            <span class="n">context</span><span class="o">=</span><span class="n">AgentContext</span><span class="p">(</span><span class="n">modality</span><span class="o">=</span><span class="s2">&quot;voice&quot;</span><span class="p">)</span>
</span><span id="__span-4-9"><a id="__codelineno-4-9" name="__codelineno-4-9" href="#__codelineno-4-9"></a>        <span class="p">)</span>
</span><span id="__span-4-10"><a id="__codelineno-4-10" name="__codelineno-4-10" href="#__codelineno-4-10"></a>    <span class="k">else</span><span class="p">:</span>
</span><span id="__span-4-11"><a id="__codelineno-4-11" name="__codelineno-4-11" href="#__codelineno-4-11"></a>        <span class="c1"># Fallback: Echo the transcript</span>
</span><span id="__span-4-12"><a id="__codelineno-4-12" name="__codelineno-4-12" href="#__codelineno-4-12"></a>        <span class="n">response_text</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;I heard you say: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_current_transcript</span><span class="si">}</span><span class="s2">&quot;</span>
</span></code></pre></div>
<p><strong>Why this design</strong>:
- <strong>Separation of concerns</strong>: Voice Pipeline handles audio I/O, Agent handles reasoning
- <strong>Consistent interface</strong>: Text-based chat and voice both use <code>process_input()</code>
- <strong>Context propagation</strong>: Agent can adjust behavior based on <code>modality="voice"</code> (e.g., shorter responses)</p>
<p><strong>Data exchange</strong>:
- <strong>Input</strong>: <code>(transcript: str, context: AgentContext)</code> - Recognized speech + metadata
- <strong>Output</strong>: <code>response_text: str</code> - Agent's response (may include tool call results)</p>
<p><strong>Error handling</strong>:
- Agent errors (e.g., Claude API timeout) raise exceptions caught by Pipeline
- Pipeline transitions to ERROR state and applies recovery strategy
- If agent is unavailable (offline mode), fallback to echo or canned responses</p>
<hr />
<h3 id="motion-integration-headwobble-during-tts">Motion Integration: HeadWobble During TTS<a class="headerlink" href="#motion-integration-headwobble-during-tts" title="Permanent link">&para;</a></h3>
<p>The HeadWobble behavior synchronizes head motion with TTS audio amplitude, creating the illusion of speech:</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-5-1"><a id="__codelineno-5-1" name="__codelineno-5-1" href="#__codelineno-5-1"></a><span class="c1"># In pipeline.py (SPEAKING state)</span>
</span><span id="__span-5-2"><a id="__codelineno-5-2" name="__codelineno-5-2" href="#__codelineno-5-2"></a><span class="k">def</span><span class="w"> </span><span class="nf">_on_audio_amplitude</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">amplitude</span><span class="p">:</span> <span class="nb">float</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-5-3"><a id="__codelineno-5-3" name="__codelineno-5-3" href="#__codelineno-5-3"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Callback for TTS audio amplitude (for HeadWobble).&quot;&quot;&quot;</span>
</span><span id="__span-5-4"><a id="__codelineno-5-4" name="__codelineno-5-4" href="#__codelineno-5-4"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">on_audio_amplitude</span><span class="p">:</span>
</span><span id="__span-5-5"><a id="__codelineno-5-5" name="__codelineno-5-5" href="#__codelineno-5-5"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">on_audio_amplitude</span><span class="p">(</span><span class="n">amplitude</span><span class="p">)</span>
</span><span id="__span-5-6"><a id="__codelineno-5-6" name="__codelineno-5-6" href="#__codelineno-5-6"></a>
</span><span id="__span-5-7"><a id="__codelineno-5-7" name="__codelineno-5-7" href="#__codelineno-5-7"></a>    <span class="c1"># Also update agent&#39;s wobble if available</span>
</span><span id="__span-5-8"><a id="__codelineno-5-8" name="__codelineno-5-8" href="#__codelineno-5-8"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">agent</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">agent</span><span class="p">,</span> <span class="s2">&quot;_wobble&quot;</span><span class="p">):</span>
</span><span id="__span-5-9"><a id="__codelineno-5-9" name="__codelineno-5-9" href="#__codelineno-5-9"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">agent</span><span class="o">.</span><span class="n">_wobble</span><span class="o">.</span><span class="n">update_amplitude</span><span class="p">(</span><span class="n">amplitude</span><span class="p">)</span>
</span></code></pre></div>
<p><strong>Data flow</strong>:
1. OpenAI Realtime emits audio chunks with amplitude metadata
2. Pipeline receives amplitude in <code>_on_audio_amplitude()</code> callback
3. Pipeline forwards to <code>HeadWobble.update_amplitude()</code>
4. HeadWobble modulates head pitch/yaw in real-time (100Hz control loop)</p>
<p><strong>Key insight</strong>: Amplitude represents the "loudness" of the current audio frame. HeadWobble uses this to create natural-looking head motion (bigger wobbles for louder syllables).</p>
<p><strong>Trade-offs</strong>:
- <strong>Pro</strong>: Very natural-looking speech animation (humans move heads when speaking)
- <strong>Con</strong>: Tight coupling between voice and motion (motion failures can break voice)
- <strong>Mitigation</strong>: Motion errors logged but don't propagate to voice pipeline</p>
<hr />
<h3 id="motion-integration-idle-behavior-pauseresume">Motion Integration: Idle Behavior Pause/Resume<a class="headerlink" href="#motion-integration-idle-behavior-pauseresume" title="Permanent link">&para;</a></h3>
<p>The idle behavior (look-around animation) must pause during conversation to avoid conflicting motions:</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-6-1"><a id="__codelineno-6-1" name="__codelineno-6-1" href="#__codelineno-6-1"></a><span class="c1"># In pipeline.py</span>
</span><span id="__span-6-2"><a id="__codelineno-6-2" name="__codelineno-6-2" href="#__codelineno-6-2"></a>
</span><span id="__span-6-3"><a id="__codelineno-6-3" name="__codelineno-6-3" href="#__codelineno-6-3"></a><span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">_handle_wake_detected</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-6-4"><a id="__codelineno-6-4" name="__codelineno-6-4" href="#__codelineno-6-4"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Handle wake word detection.&quot;&quot;&quot;</span>
</span><span id="__span-6-5"><a id="__codelineno-6-5" name="__codelineno-6-5" href="#__codelineno-6-5"></a>    <span class="c1"># Pause idle behavior when entering conversation</span>
</span><span id="__span-6-6"><a id="__codelineno-6-6" name="__codelineno-6-6" href="#__codelineno-6-6"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">agent</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">agent</span><span class="p">,</span> <span class="s2">&quot;_blend_controller&quot;</span><span class="p">):</span>
</span><span id="__span-6-7"><a id="__codelineno-6-7" name="__codelineno-6-7" href="#__codelineno-6-7"></a>        <span class="k">await</span> <span class="bp">self</span><span class="o">.</span><span class="n">agent</span><span class="o">.</span><span class="n">_blend_controller</span><span class="o">.</span><span class="n">pause_idle_behavior</span><span class="p">()</span>
</span><span id="__span-6-8"><a id="__codelineno-6-8" name="__codelineno-6-8" href="#__codelineno-6-8"></a>
</span><span id="__span-6-9"><a id="__codelineno-6-9" name="__codelineno-6-9" href="#__codelineno-6-9"></a><span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">_resume_idle_behavior</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-6-10"><a id="__codelineno-6-10" name="__codelineno-6-10" href="#__codelineno-6-10"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Resume idle behavior when returning to wake word listening.&quot;&quot;&quot;</span>
</span><span id="__span-6-11"><a id="__codelineno-6-11" name="__codelineno-6-11" href="#__codelineno-6-11"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">agent</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">agent</span><span class="p">,</span> <span class="s2">&quot;_blend_controller&quot;</span><span class="p">):</span>
</span><span id="__span-6-12"><a id="__codelineno-6-12" name="__codelineno-6-12" href="#__codelineno-6-12"></a>        <span class="k">await</span> <span class="bp">self</span><span class="o">.</span><span class="n">agent</span><span class="o">.</span><span class="n">_blend_controller</span><span class="o">.</span><span class="n">resume_idle_behavior</span><span class="p">()</span>
</span></code></pre></div>
<p><strong>When paused</strong>:
- WAKE_DETECTED state (wake word heard, waiting for speech)
- LISTENING_SPEECH state (user speaking)
- PROCESSING state (waiting for Claude response)
- SPEAKING state (TTS playback)</p>
<p><strong>When resumed</strong>:
- LISTENING_WAKE state (back to wake word detection)
- ERROR state (after recovery completes)</p>
<p><strong>Why this matters</strong>: Without pausing, the idle behavior would fight with HeadWobble for motor control, creating jerky, unnatural motion. The <code>BlendController</code> arbitrates between motion sources, but explicit pause/resume is cleaner.</p>
<hr />
<h3 id="persona-integration-deferred-switching-after-tts">Persona Integration: Deferred Switching After TTS<a class="headerlink" href="#persona-integration-deferred-switching-after-tts" title="Permanent link">&para;</a></h3>
<p>Persona switches happen in two phases:</p>
<p><strong>Phase 1: Wake Word Detection (Mark Pending)</strong>
<div class="language-python highlight"><pre><span></span><code><span id="__span-7-1"><a id="__codelineno-7-1" name="__codelineno-7-1" href="#__codelineno-7-1"></a><span class="k">def</span><span class="w"> </span><span class="nf">_on_wake_word_detected</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">detected_model</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-7-2"><a id="__codelineno-7-2" name="__codelineno-7-2" href="#__codelineno-7-2"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Map wake word model to persona and mark for deferred switch.&quot;&quot;&quot;</span>
</span><span id="__span-7-3"><a id="__codelineno-7-3" name="__codelineno-7-3" href="#__codelineno-7-3"></a>    <span class="n">persona</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_wake_word_to_persona</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">detected_model</span><span class="p">)</span>
</span><span id="__span-7-4"><a id="__codelineno-7-4" name="__codelineno-7-4" href="#__codelineno-7-4"></a>    <span class="k">if</span> <span class="n">persona</span> <span class="ow">and</span> <span class="n">persona</span><span class="o">.</span><span class="n">name</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_current_persona</span><span class="o">.</span><span class="n">name</span><span class="p">:</span>
</span><span id="__span-7-5"><a id="__codelineno-7-5" name="__codelineno-7-5" href="#__codelineno-7-5"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_pending_persona_switch</span> <span class="o">=</span> <span class="n">persona</span>
</span><span id="__span-7-6"><a id="__codelineno-7-6" name="__codelineno-7-6" href="#__codelineno-7-6"></a>        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;persona_switch_pending&quot;</span><span class="p">,</span> <span class="n">new_persona</span><span class="o">=</span><span class="n">persona</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
</span></code></pre></div></p>
<p><strong>Phase 2: After TTS Playback (Apply Switch)</strong>
<div class="language-python highlight"><pre><span></span><code><span id="__span-8-1"><a id="__codelineno-8-1" name="__codelineno-8-1" href="#__codelineno-8-1"></a><span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">_play_response</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-8-2"><a id="__codelineno-8-2" name="__codelineno-8-2" href="#__codelineno-8-2"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Play TTS response, then apply pending persona switch.&quot;&quot;&quot;</span>
</span><span id="__span-8-3"><a id="__codelineno-8-3" name="__codelineno-8-3" href="#__codelineno-8-3"></a>    <span class="c1"># ... play audio chunks ...</span>
</span><span id="__span-8-4"><a id="__codelineno-8-4" name="__codelineno-8-4" href="#__codelineno-8-4"></a>
</span><span id="__span-8-5"><a id="__codelineno-8-5" name="__codelineno-8-5" href="#__codelineno-8-5"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_pending_persona_switch</span><span class="p">:</span>
</span><span id="__span-8-6"><a id="__codelineno-8-6" name="__codelineno-8-6" href="#__codelineno-8-6"></a>        <span class="k">await</span> <span class="bp">self</span><span class="o">.</span><span class="n">_apply_persona_switch</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_pending_persona_switch</span><span class="p">)</span>
</span><span id="__span-8-7"><a id="__codelineno-8-7" name="__codelineno-8-7" href="#__codelineno-8-7"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_pending_persona_switch</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="__span-8-8"><a id="__codelineno-8-8" name="__codelineno-8-8" href="#__codelineno-8-8"></a>
</span><span id="__span-8-9"><a id="__codelineno-8-9" name="__codelineno-8-9" href="#__codelineno-8-9"></a><span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">_apply_persona_switch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">persona</span><span class="p">:</span> <span class="n">PersonaConfig</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-8-10"><a id="__codelineno-8-10" name="__codelineno-8-10" href="#__codelineno-8-10"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Reconnect WebSocket with new voice and update current persona.&quot;&quot;&quot;</span>
</span><span id="__span-8-11"><a id="__codelineno-8-11" name="__codelineno-8-11" href="#__codelineno-8-11"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">_current_persona</span> <span class="o">=</span> <span class="n">persona</span>
</span><span id="__span-8-12"><a id="__codelineno-8-12" name="__codelineno-8-12" href="#__codelineno-8-12"></a>
</span><span id="__span-8-13"><a id="__codelineno-8-13" name="__codelineno-8-13" href="#__codelineno-8-13"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_openai</span><span class="p">:</span>
</span><span id="__span-8-14"><a id="__codelineno-8-14" name="__codelineno-8-14" href="#__codelineno-8-14"></a>        <span class="k">await</span> <span class="bp">self</span><span class="o">.</span><span class="n">_openai</span><span class="o">.</span><span class="n">disconnect</span><span class="p">()</span>
</span><span id="__span-8-15"><a id="__codelineno-8-15" name="__codelineno-8-15" href="#__codelineno-8-15"></a>        <span class="k">await</span> <span class="bp">self</span><span class="o">.</span><span class="n">_openai</span><span class="o">.</span><span class="n">connect</span><span class="p">(</span><span class="n">voice</span><span class="o">=</span><span class="n">persona</span><span class="o">.</span><span class="n">voice</span><span class="p">)</span>
</span></code></pre></div></p>
<p><strong>Why deferred</strong>: OpenAI Realtime sessions are voice-scoped. Switching voices mid-session requires disconnecting and reconnecting the WebSocket, which would interrupt TTS playback.</p>
<p><strong>Agent notification</strong>: After switching, pipeline can optionally notify agent to reload system prompt:
<div class="language-python highlight"><pre><span></span><code><span id="__span-9-1"><a id="__codelineno-9-1" name="__codelineno-9-1" href="#__codelineno-9-1"></a><span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">agent</span><span class="p">:</span>
</span><span id="__span-9-2"><a id="__codelineno-9-2" name="__codelineno-9-2" href="#__codelineno-9-2"></a>    <span class="k">await</span> <span class="bp">self</span><span class="o">.</span><span class="n">agent</span><span class="o">.</span><span class="n">load_persona_prompt</span><span class="p">(</span><span class="n">persona</span><span class="o">.</span><span class="n">prompt_path</span><span class="p">)</span>
</span></code></pre></div></p>
<h2 id="error-handling-recovery">Error Handling &amp; Recovery<a class="headerlink" href="#error-handling-recovery" title="Permanent link">&para;</a></h2>
<p>The Voice Pipeline implements a three-tier recovery strategy:</p>
<h3 id="tier-1-retry-with-exponential-backoff">Tier 1: Retry with Exponential Backoff<a class="headerlink" href="#tier-1-retry-with-exponential-backoff" title="Permanent link">&para;</a></h3>
<p>For transient errors (network glitches, temporary hardware issues):</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-10-1"><a id="__codelineno-10-1" name="__codelineno-10-1" href="#__codelineno-10-1"></a><span class="nd">@dataclass</span>
</span><span id="__span-10-2"><a id="__codelineno-10-2" name="__codelineno-10-2" href="#__codelineno-10-2"></a><span class="k">class</span><span class="w"> </span><span class="nc">RecoveryStrategy</span><span class="p">:</span>
</span><span id="__span-10-3"><a id="__codelineno-10-3" name="__codelineno-10-3" href="#__codelineno-10-3"></a>    <span class="n">max_retries</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span>
</span><span id="__span-10-4"><a id="__codelineno-10-4" name="__codelineno-10-4" href="#__codelineno-10-4"></a>    <span class="n">initial_delay_seconds</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span>
</span><span id="__span-10-5"><a id="__codelineno-10-5" name="__codelineno-10-5" href="#__codelineno-10-5"></a>    <span class="n">backoff_factor</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">2.0</span>  <span class="c1"># 1s → 2s → 4s</span>
</span><span id="__span-10-6"><a id="__codelineno-10-6" name="__codelineno-10-6" href="#__codelineno-10-6"></a>    <span class="n">max_delay_seconds</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">30.0</span>
</span></code></pre></div>
<p><strong>Applied to</strong>:
- OpenAI WebSocket connection failures
- Audio device initialization errors
- Temporary daemon communication failures</p>
<p><strong>Example flow</strong>:
1. Attempt 1 fails → Wait 1 second
2. Attempt 2 fails → Wait 2 seconds
3. Attempt 3 fails → Wait 4 seconds
4. Max retries exceeded → Move to Tier 2</p>
<hr />
<h3 id="tier-2-degraded-mode-operation">Tier 2: Degraded Mode Operation<a class="headerlink" href="#tier-2-degraded-mode-operation" title="Permanent link">&para;</a></h3>
<p>When a component repeatedly fails, gracefully degrade functionality:</p>
<table>
<thead>
<tr>
<th>Component Failure</th>
<th>Degraded Mode Behavior</th>
</tr>
</thead>
<tbody>
<tr>
<td>Wake Word Detector</td>
<td>Switch to always-listening mode (skip wake word)</td>
</tr>
<tr>
<td>Silero VAD</td>
<td>Fall back to energy-based VAD (simple amplitude threshold)</td>
</tr>
<tr>
<td>OpenAI Realtime</td>
<td>Fall back to batch STT/TTS (higher latency)</td>
</tr>
<tr>
<td>TTS Playback</td>
<td>Log response text to console (text-only mode)</td>
</tr>
</tbody>
</table>
<p><strong>Configuration</strong> (in <code>config/default.yaml</code>):
<div class="language-yaml highlight"><pre><span></span><code><span id="__span-11-1"><a id="__codelineno-11-1" name="__codelineno-11-1" href="#__codelineno-11-1"></a><span class="nt">degraded_mode</span><span class="p">:</span>
</span><span id="__span-11-2"><a id="__codelineno-11-2" name="__codelineno-11-2" href="#__codelineno-11-2"></a><span class="w">  </span><span class="nt">skip_wake_word_on_failure</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
</span><span id="__span-11-3"><a id="__codelineno-11-3" name="__codelineno-11-3" href="#__codelineno-11-3"></a><span class="w">  </span><span class="nt">use_energy_vad_fallback</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
</span><span id="__span-11-4"><a id="__codelineno-11-4" name="__codelineno-11-4" href="#__codelineno-11-4"></a><span class="w">  </span><span class="nt">log_response_on_tts_failure</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
</span></code></pre></div></p>
<p><strong>Degraded mode tracking</strong>:
<div class="language-python highlight"><pre><span></span><code><span id="__span-12-1"><a id="__codelineno-12-1" name="__codelineno-12-1" href="#__codelineno-12-1"></a><span class="c1"># In pipeline.py</span>
</span><span id="__span-12-2"><a id="__codelineno-12-2" name="__codelineno-12-2" href="#__codelineno-12-2"></a><span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_recovery</span><span class="o">.</span><span class="n">is_degraded</span><span class="p">(</span><span class="s2">&quot;wake_word&quot;</span><span class="p">):</span>
</span><span id="__span-12-3"><a id="__codelineno-12-3" name="__codelineno-12-3" href="#__codelineno-12-3"></a>    <span class="c1"># Skip wake word, go directly to LISTENING_SPEECH</span>
</span><span id="__span-12-4"><a id="__codelineno-12-4" name="__codelineno-12-4" href="#__codelineno-12-4"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">_set_state</span><span class="p">(</span><span class="n">VoicePipelineState</span><span class="o">.</span><span class="n">LISTENING_SPEECH</span><span class="p">)</span>
</span></code></pre></div></p>
<hr />
<h3 id="tier-3-abort-and-notify">Tier 3: Abort and Notify<a class="headerlink" href="#tier-3-abort-and-notify" title="Permanent link">&para;</a></h3>
<p>If degraded mode still fails, abort the current operation and notify the user:</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-13-1"><a id="__codelineno-13-1" name="__codelineno-13-1" href="#__codelineno-13-1"></a><span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">_handle_error</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-13-2"><a id="__codelineno-13-2" name="__codelineno-13-2" href="#__codelineno-13-2"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Handle ERROR state with recovery or abort.&quot;&quot;&quot;</span>
</span><span id="__span-13-3"><a id="__codelineno-13-3" name="__codelineno-13-3" href="#__codelineno-13-3"></a>
</span><span id="__span-13-4"><a id="__codelineno-13-4" name="__codelineno-13-4" href="#__codelineno-13-4"></a>    <span class="c1"># Apply recovery strategy</span>
</span><span id="__span-13-5"><a id="__codelineno-13-5" name="__codelineno-13-5" href="#__codelineno-13-5"></a>    <span class="n">action</span> <span class="o">=</span> <span class="k">await</span> <span class="bp">self</span><span class="o">.</span><span class="n">_recovery</span><span class="o">.</span><span class="n">recover</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_last_error</span><span class="p">)</span>
</span><span id="__span-13-6"><a id="__codelineno-13-6" name="__codelineno-13-6" href="#__codelineno-13-6"></a>
</span><span id="__span-13-7"><a id="__codelineno-13-7" name="__codelineno-13-7" href="#__codelineno-13-7"></a>    <span class="k">if</span> <span class="n">action</span> <span class="o">==</span> <span class="n">RecoveryAction</span><span class="o">.</span><span class="n">RETRY</span><span class="p">:</span>
</span><span id="__span-13-8"><a id="__codelineno-13-8" name="__codelineno-13-8" href="#__codelineno-13-8"></a>        <span class="c1"># Retry the failed state</span>
</span><span id="__span-13-9"><a id="__codelineno-13-9" name="__codelineno-13-9" href="#__codelineno-13-9"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_set_state</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_last_good_state</span><span class="p">)</span>
</span><span id="__span-13-10"><a id="__codelineno-13-10" name="__codelineno-13-10" href="#__codelineno-13-10"></a>
</span><span id="__span-13-11"><a id="__codelineno-13-11" name="__codelineno-13-11" href="#__codelineno-13-11"></a>    <span class="k">elif</span> <span class="n">action</span> <span class="o">==</span> <span class="n">RecoveryAction</span><span class="o">.</span><span class="n">DEGRADE</span><span class="p">:</span>
</span><span id="__span-13-12"><a id="__codelineno-13-12" name="__codelineno-13-12" href="#__codelineno-13-12"></a>        <span class="c1"># Enable degraded mode</span>
</span><span id="__span-13-13"><a id="__codelineno-13-13" name="__codelineno-13-13" href="#__codelineno-13-13"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_recovery</span><span class="o">.</span><span class="n">mark_degraded</span><span class="p">(</span><span class="n">component_name</span><span class="p">)</span>
</span><span id="__span-13-14"><a id="__codelineno-13-14" name="__codelineno-13-14" href="#__codelineno-13-14"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_restart_listening</span><span class="p">()</span>
</span><span id="__span-13-15"><a id="__codelineno-13-15" name="__codelineno-13-15" href="#__codelineno-13-15"></a>
</span><span id="__span-13-16"><a id="__codelineno-13-16" name="__codelineno-13-16" href="#__codelineno-13-16"></a>    <span class="k">elif</span> <span class="n">action</span> <span class="o">==</span> <span class="n">RecoveryAction</span><span class="o">.</span><span class="n">ABORT</span><span class="p">:</span>
</span><span id="__span-13-17"><a id="__codelineno-13-17" name="__codelineno-13-17" href="#__codelineno-13-17"></a>        <span class="c1"># Stop pipeline, notify user</span>
</span><span id="__span-13-18"><a id="__codelineno-13-18" name="__codelineno-13-18" href="#__codelineno-13-18"></a>        <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="s2">&quot;voice_pipeline_aborted&quot;</span><span class="p">,</span> <span class="n">error</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_last_error</span><span class="p">)</span>
</span><span id="__span-13-19"><a id="__codelineno-13-19" name="__codelineno-13-19" href="#__codelineno-13-19"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_set_state</span><span class="p">(</span><span class="n">VoicePipelineState</span><span class="o">.</span><span class="n">IDLE</span><span class="p">)</span>
</span><span id="__span-13-20"><a id="__codelineno-13-20" name="__codelineno-13-20" href="#__codelineno-13-20"></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">on_error</span><span class="p">:</span>
</span><span id="__span-13-21"><a id="__codelineno-13-21" name="__codelineno-13-21" href="#__codelineno-13-21"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">on_error</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_last_error</span><span class="p">)</span>
</span></code></pre></div>
<p><strong>User notification strategies</strong>:
- <strong>LED indicator</strong>: Antennas turn red during ERROR state
- <strong>Audible beep</strong>: Three short beeps indicate critical failure
- <strong>Log message</strong>: Console shows detailed error for debugging
- <strong>Agent message</strong>: If agent is available, say "I'm having trouble with my microphone"</p>
<hr />
<h3 id="timeout-guards-preventing-stuck-states">Timeout Guards: Preventing Stuck States<a class="headerlink" href="#timeout-guards-preventing-stuck-states" title="Permanent link">&para;</a></h3>
<p>Every state with a timeout has a background task that forces recovery:</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-14-1"><a id="__codelineno-14-1" name="__codelineno-14-1" href="#__codelineno-14-1"></a><span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">_state_timeout_guard</span><span class="p">(</span>
</span><span id="__span-14-2"><a id="__codelineno-14-2" name="__codelineno-14-2" href="#__codelineno-14-2"></a>    <span class="bp">self</span><span class="p">,</span> <span class="n">expected_state</span><span class="p">:</span> <span class="n">VoicePipelineState</span><span class="p">,</span> <span class="n">timeout</span><span class="p">:</span> <span class="nb">float</span>
</span><span id="__span-14-3"><a id="__codelineno-14-3" name="__codelineno-14-3" href="#__codelineno-14-3"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-14-4"><a id="__codelineno-14-4" name="__codelineno-14-4" href="#__codelineno-14-4"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Force ERROR transition if state exceeds timeout.&quot;&quot;&quot;</span>
</span><span id="__span-14-5"><a id="__codelineno-14-5" name="__codelineno-14-5" href="#__codelineno-14-5"></a>
</span><span id="__span-14-6"><a id="__codelineno-14-6" name="__codelineno-14-6" href="#__codelineno-14-6"></a>    <span class="k">await</span> <span class="n">asyncio</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="n">timeout</span><span class="p">)</span>
</span><span id="__span-14-7"><a id="__codelineno-14-7" name="__codelineno-14-7" href="#__codelineno-14-7"></a>
</span><span id="__span-14-8"><a id="__codelineno-14-8" name="__codelineno-14-8" href="#__codelineno-14-8"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_state</span> <span class="o">==</span> <span class="n">expected_state</span><span class="p">:</span>
</span><span id="__span-14-9"><a id="__codelineno-14-9" name="__codelineno-14-9" href="#__codelineno-14-9"></a>        <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span>
</span><span id="__span-14-10"><a id="__codelineno-14-10" name="__codelineno-14-10" href="#__codelineno-14-10"></a>            <span class="s2">&quot;state_timeout&quot;</span><span class="p">,</span>
</span><span id="__span-14-11"><a id="__codelineno-14-11" name="__codelineno-14-11" href="#__codelineno-14-11"></a>            <span class="n">state</span><span class="o">=</span><span class="n">expected_state</span><span class="o">.</span><span class="n">value</span><span class="p">,</span>
</span><span id="__span-14-12"><a id="__codelineno-14-12" name="__codelineno-14-12" href="#__codelineno-14-12"></a>            <span class="n">timeout</span><span class="o">=</span><span class="n">timeout</span><span class="p">,</span>
</span><span id="__span-14-13"><a id="__codelineno-14-13" name="__codelineno-14-13" href="#__codelineno-14-13"></a>            <span class="n">duration</span><span class="o">=</span><span class="n">time</span><span class="o">.</span><span class="n">monotonic</span><span class="p">()</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">_state_entered_at</span><span class="p">,</span>
</span><span id="__span-14-14"><a id="__codelineno-14-14" name="__codelineno-14-14" href="#__codelineno-14-14"></a>        <span class="p">)</span>
</span><span id="__span-14-15"><a id="__codelineno-14-15" name="__codelineno-14-15" href="#__codelineno-14-15"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_last_error</span> <span class="o">=</span> <span class="n">VoicePipelineError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Timeout in </span><span class="si">{</span><span class="n">expected_state</span><span class="o">.</span><span class="n">value</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="__span-14-16"><a id="__codelineno-14-16" name="__codelineno-14-16" href="#__codelineno-14-16"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_set_state</span><span class="p">(</span><span class="n">VoicePipelineState</span><span class="o">.</span><span class="n">ERROR</span><span class="p">)</span>
</span></code></pre></div>
<p><strong>Timeout values</strong> (from <code>STATE_TIMEOUTS</code>):
- WAKE_DETECTED: 2s (should quickly transition to LISTENING_SPEECH)
- LISTENING_SPEECH: 35s (max speech duration + buffer)
- PROCESSING: 90s (Claude response, including tool calls)
- SPEAKING: 180s (3 minutes max for long philosophical responses)
- ERROR: 10s (brief pause before retry)</p>
<p><strong>Why needed</strong>: Without timeouts, a hung WebSocket or infinite VAD loop would freeze the pipeline indefinitely. Timeouts provide automatic recovery.</p>
<hr />
<h3 id="health-monitoring-stream-disconnection-detection">Health Monitoring: Stream Disconnection Detection<a class="headerlink" href="#health-monitoring-stream-disconnection-detection" title="Permanent link">&para;</a></h3>
<p>The AudioManager continuously monitors stream health:</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-15-1"><a id="__codelineno-15-1" name="__codelineno-15-1" href="#__codelineno-15-1"></a><span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">_health_check_loop</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-15-2"><a id="__codelineno-15-2" name="__codelineno-15-2" href="#__codelineno-15-2"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Background task that monitors stream health.&quot;&quot;&quot;</span>
</span><span id="__span-15-3"><a id="__codelineno-15-3" name="__codelineno-15-3" href="#__codelineno-15-3"></a>
</span><span id="__span-15-4"><a id="__codelineno-15-4" name="__codelineno-15-4" href="#__codelineno-15-4"></a>    <span class="k">while</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_recording</span><span class="p">:</span>
</span><span id="__span-15-5"><a id="__codelineno-15-5" name="__codelineno-15-5" href="#__codelineno-15-5"></a>        <span class="k">await</span> <span class="n">asyncio</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">health_check_interval_seconds</span><span class="p">)</span>
</span><span id="__span-15-6"><a id="__codelineno-15-6" name="__codelineno-15-6" href="#__codelineno-15-6"></a>
</span><span id="__span-15-7"><a id="__codelineno-15-7" name="__codelineno-15-7" href="#__codelineno-15-7"></a>        <span class="c1"># Check for stale data (no reads in last 2 intervals)</span>
</span><span id="__span-15-8"><a id="__codelineno-15-8" name="__codelineno-15-8" href="#__codelineno-15-8"></a>        <span class="n">time_since_read</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">monotonic</span><span class="p">()</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">_last_successful_read</span>
</span><span id="__span-15-9"><a id="__codelineno-15-9" name="__codelineno-15-9" href="#__codelineno-15-9"></a>        <span class="k">if</span> <span class="n">time_since_read</span> <span class="o">&gt;</span> <span class="mi">2</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">health_check_interval_seconds</span><span class="p">:</span>
</span><span id="__span-15-10"><a id="__codelineno-15-10" name="__codelineno-15-10" href="#__codelineno-15-10"></a>            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
</span><span id="__span-15-11"><a id="__codelineno-15-11" name="__codelineno-15-11" href="#__codelineno-15-11"></a>                <span class="s2">&quot;audio_stream_stale&quot;</span><span class="p">,</span>
</span><span id="__span-15-12"><a id="__codelineno-15-12" name="__codelineno-15-12" href="#__codelineno-15-12"></a>                <span class="n">time_since_read</span><span class="o">=</span><span class="n">time_since_read</span><span class="p">,</span>
</span><span id="__span-15-13"><a id="__codelineno-15-13" name="__codelineno-15-13" href="#__codelineno-15-13"></a>            <span class="p">)</span>
</span><span id="__span-15-14"><a id="__codelineno-15-14" name="__codelineno-15-14" href="#__codelineno-15-14"></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">on_device_error</span><span class="p">:</span>
</span><span id="__span-15-15"><a id="__codelineno-15-15" name="__codelineno-15-15" href="#__codelineno-15-15"></a>                <span class="bp">self</span><span class="o">.</span><span class="n">on_device_error</span><span class="p">(</span><span class="n">AudioDeviceError</span><span class="p">(</span><span class="s2">&quot;Stream appears disconnected&quot;</span><span class="p">))</span>
</span></code></pre></div>
<p><strong>Detected failures</strong>:
- Microphone unplugged (read returns empty data)
- Speaker disconnected (playback raises IOError)
- ALSA device released by another process</p>
<p><strong>Recovery</strong>: Pipeline receives <code>on_device_error()</code> callback, transitions to ERROR state, attempts audio reinitialization.</p>
<h2 id="configuration-reference">Configuration Reference<a class="headerlink" href="#configuration-reference" title="Permanent link">&para;</a></h2>
<p>All voice settings are in <code>config/default.yaml</code> under the <code>voice:</code> section:</p>
<h3 id="top-level-settings">Top-Level Settings<a class="headerlink" href="#top-level-settings" title="Permanent link">&para;</a></h3>
<div class="language-yaml highlight"><pre><span></span><code><span id="__span-16-1"><a id="__codelineno-16-1" name="__codelineno-16-1" href="#__codelineno-16-1"></a><span class="nt">voice</span><span class="p">:</span>
</span><span id="__span-16-2"><a id="__codelineno-16-2" name="__codelineno-16-2" href="#__codelineno-16-2"></a><span class="w">  </span><span class="nt">enabled</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span><span class="w">                 </span><span class="c1"># Enable with --voice flag</span>
</span><span id="__span-16-3"><a id="__codelineno-16-3" name="__codelineno-16-3" href="#__codelineno-16-3"></a><span class="w">  </span><span class="nt">default_persona</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">hey_motoko</span><span class="w">    </span><span class="c1"># Persona to use before wake word detected</span>
</span><span id="__span-16-4"><a id="__codelineno-16-4" name="__codelineno-16-4" href="#__codelineno-16-4"></a><span class="w">  </span><span class="nt">confirmation_beep</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span><span class="w">        </span><span class="c1"># Play sound when wake word detected</span>
</span><span id="__span-16-5"><a id="__codelineno-16-5" name="__codelineno-16-5" href="#__codelineno-16-5"></a><span class="w">  </span><span class="nt">auto_restart</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span><span class="w">             </span><span class="c1"># Restart listening after response</span>
</span></code></pre></div>
<h3 id="personas-multi-wake-word">Personas (Multi-Wake Word)<a class="headerlink" href="#personas-multi-wake-word" title="Permanent link">&para;</a></h3>
<div class="language-yaml highlight"><pre><span></span><code><span id="__span-17-1"><a id="__codelineno-17-1" name="__codelineno-17-1" href="#__codelineno-17-1"></a><span class="nt">personas</span><span class="p">:</span>
</span><span id="__span-17-2"><a id="__codelineno-17-2" name="__codelineno-17-2" href="#__codelineno-17-2"></a><span class="w">  </span><span class="nt">hey_motoko</span><span class="p">:</span>
</span><span id="__span-17-3"><a id="__codelineno-17-3" name="__codelineno-17-3" href="#__codelineno-17-3"></a><span class="w">    </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">motoko</span>
</span><span id="__span-17-4"><a id="__codelineno-17-4" name="__codelineno-17-4" href="#__codelineno-17-4"></a><span class="w">    </span><span class="nt">display_name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Major Kusanagi</span>
</span><span id="__span-17-5"><a id="__codelineno-17-5" name="__codelineno-17-5" href="#__codelineno-17-5"></a><span class="w">    </span><span class="nt">voice</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">nova</span><span class="w">                </span><span class="c1"># OpenAI TTS voice (female, analytical)</span>
</span><span id="__span-17-6"><a id="__codelineno-17-6" name="__codelineno-17-6" href="#__codelineno-17-6"></a><span class="w">    </span><span class="nt">prompt_path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">prompts/personas/motoko.md</span>
</span><span id="__span-17-7"><a id="__codelineno-17-7" name="__codelineno-17-7" href="#__codelineno-17-7"></a>
</span><span id="__span-17-8"><a id="__codelineno-17-8" name="__codelineno-17-8" href="#__codelineno-17-8"></a><span class="w">  </span><span class="nt">hey_batou</span><span class="p">:</span>
</span><span id="__span-17-9"><a id="__codelineno-17-9" name="__codelineno-17-9" href="#__codelineno-17-9"></a><span class="w">    </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">batou</span>
</span><span id="__span-17-10"><a id="__codelineno-17-10" name="__codelineno-17-10" href="#__codelineno-17-10"></a><span class="w">    </span><span class="nt">display_name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Batou</span>
</span><span id="__span-17-11"><a id="__codelineno-17-11" name="__codelineno-17-11" href="#__codelineno-17-11"></a><span class="w">    </span><span class="nt">voice</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">onyx</span><span class="w">                </span><span class="c1"># OpenAI TTS voice (male, casual)</span>
</span><span id="__span-17-12"><a id="__codelineno-17-12" name="__codelineno-17-12" href="#__codelineno-17-12"></a><span class="w">    </span><span class="nt">prompt_path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">prompts/personas/batou.md</span>
</span></code></pre></div>
<p><strong>Valid TTS voices</strong>: <code>alloy</code>, <code>echo</code>, <code>fable</code>, <code>onyx</code>, <code>nova</code>, <code>shimmer</code></p>
<h3 id="wake-word-detection">Wake Word Detection<a class="headerlink" href="#wake-word-detection" title="Permanent link">&para;</a></h3>
<div class="language-yaml highlight"><pre><span></span><code><span id="__span-18-1"><a id="__codelineno-18-1" name="__codelineno-18-1" href="#__codelineno-18-1"></a><span class="nt">wake_word</span><span class="p">:</span>
</span><span id="__span-18-2"><a id="__codelineno-18-2" name="__codelineno-18-2" href="#__codelineno-18-2"></a><span class="w">  </span><span class="nt">enabled</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
</span><span id="__span-18-3"><a id="__codelineno-18-3" name="__codelineno-18-3" href="#__codelineno-18-3"></a><span class="w">  </span><span class="nt">model</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">hey_jarvis</span><span class="w">            </span><span class="c1"># Fallback if no persona models found</span>
</span><span id="__span-18-4"><a id="__codelineno-18-4" name="__codelineno-18-4" href="#__codelineno-18-4"></a><span class="w">  </span><span class="nt">sensitivity</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.5</span><span class="w">             </span><span class="c1"># 0.0 (strict) to 1.0 (lenient)</span>
</span><span id="__span-18-5"><a id="__codelineno-18-5" name="__codelineno-18-5" href="#__codelineno-18-5"></a><span class="w">  </span><span class="nt">cooldown_seconds</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">2.0</span><span class="w">        </span><span class="c1"># Ignore detections for this period</span>
</span><span id="__span-18-6"><a id="__codelineno-18-6" name="__codelineno-18-6" href="#__codelineno-18-6"></a><span class="w">  </span><span class="nt">custom_models_dir</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">data/wake_words</span><span class="w">  </span><span class="c1"># .onnx model directory</span>
</span></code></pre></div>
<p><strong>Model sources</strong>:
1. Custom models in <code>data/wake_words/*.onnx</code> (persona-specific)
2. Bundled OpenWakeWord models (hey_jarvis, alexa, hey_mycroft)</p>
<h3 id="voice-activity-detection-vad">Voice Activity Detection (VAD)<a class="headerlink" href="#voice-activity-detection-vad" title="Permanent link">&para;</a></h3>
<div class="language-yaml highlight"><pre><span></span><code><span id="__span-19-1"><a id="__codelineno-19-1" name="__codelineno-19-1" href="#__codelineno-19-1"></a><span class="nt">vad</span><span class="p">:</span>
</span><span id="__span-19-2"><a id="__codelineno-19-2" name="__codelineno-19-2" href="#__codelineno-19-2"></a><span class="w">  </span><span class="nt">silence_threshold_ms</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">800</span><span class="w">    </span><span class="c1"># Silence duration to trigger end-of-speech</span>
</span><span id="__span-19-3"><a id="__codelineno-19-3" name="__codelineno-19-3" href="#__codelineno-19-3"></a><span class="w">  </span><span class="nt">min_speech_duration_ms</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">250</span><span class="w">  </span><span class="c1"># Minimum speech to be valid (filter coughs)</span>
</span><span id="__span-19-4"><a id="__codelineno-19-4" name="__codelineno-19-4" href="#__codelineno-19-4"></a><span class="w">  </span><span class="nt">max_speech_duration_s</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">30.0</span><span class="w">  </span><span class="c1"># Maximum before timeout (prevents infinite recording)</span>
</span><span id="__span-19-5"><a id="__codelineno-19-5" name="__codelineno-19-5" href="#__codelineno-19-5"></a><span class="w">  </span><span class="nt">speech_threshold</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.5</span><span class="w">        </span><span class="c1"># VAD sensitivity (0.0-1.0, higher = more sensitive)</span>
</span></code></pre></div>
<p><strong>Tuning guide</strong>:
- <strong>silence_threshold_ms</strong>: Lower = more responsive (cuts off sooner), higher = less interruption
- <strong>speech_threshold</strong>: Lower = requires clearer speech, higher = more sensitive to noise</p>
<h3 id="openai-realtime-api">OpenAI Realtime API<a class="headerlink" href="#openai-realtime-api" title="Permanent link">&para;</a></h3>
<div class="language-yaml highlight"><pre><span></span><code><span id="__span-20-1"><a id="__codelineno-20-1" name="__codelineno-20-1" href="#__codelineno-20-1"></a><span class="nt">openai</span><span class="p">:</span>
</span><span id="__span-20-2"><a id="__codelineno-20-2" name="__codelineno-20-2" href="#__codelineno-20-2"></a><span class="w">  </span><span class="nt">model</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">gpt-realtime-mini</span><span class="w">     </span><span class="c1"># Cost-efficient, low latency (~1 second)</span>
</span><span id="__span-20-3"><a id="__codelineno-20-3" name="__codelineno-20-3" href="#__codelineno-20-3"></a><span class="w">  </span><span class="nt">voice</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">alloy</span><span class="w">                 </span><span class="c1"># Default voice (overridden by persona)</span>
</span><span id="__span-20-4"><a id="__codelineno-20-4" name="__codelineno-20-4" href="#__codelineno-20-4"></a><span class="w">  </span><span class="nt">sample_rate</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">24000</span><span class="w">           </span><span class="c1"># OpenAI uses 24kHz (don&#39;t change)</span>
</span><span id="__span-20-5"><a id="__codelineno-20-5" name="__codelineno-20-5" href="#__codelineno-20-5"></a><span class="w">  </span><span class="nt">temperature</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.8</span><span class="w">             </span><span class="c1"># Response creativity (0.0-1.0)</span>
</span><span id="__span-20-6"><a id="__codelineno-20-6" name="__codelineno-20-6" href="#__codelineno-20-6"></a><span class="w">  </span><span class="nt">max_response_tokens</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">4096</span><span class="w">    </span><span class="c1"># Max response length</span>
</span><span id="__span-20-7"><a id="__codelineno-20-7" name="__codelineno-20-7" href="#__codelineno-20-7"></a><span class="w">  </span><span class="nt">turn_detection_threshold</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.5</span><span class="w">    </span><span class="c1"># Unused (manual VAD mode)</span>
</span><span id="__span-20-8"><a id="__codelineno-20-8" name="__codelineno-20-8" href="#__codelineno-20-8"></a><span class="w">  </span><span class="nt">turn_detection_silence_ms</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">500</span><span class="w">   </span><span class="c1"># Unused (manual VAD mode)</span>
</span></code></pre></div>
<p><strong>Model options</strong>:
- <code>gpt-realtime-mini</code>: $0.06/min input, $0.24/min output (recommended)
- <code>gpt-4-realtime</code>: Higher quality, higher cost</p>
<h3 id="audio-hardware">Audio Hardware<a class="headerlink" href="#audio-hardware" title="Permanent link">&para;</a></h3>
<div class="language-yaml highlight"><pre><span></span><code><span id="__span-21-1"><a id="__codelineno-21-1" name="__codelineno-21-1" href="#__codelineno-21-1"></a><span class="nt">audio</span><span class="p">:</span>
</span><span id="__span-21-2"><a id="__codelineno-21-2" name="__codelineno-21-2" href="#__codelineno-21-2"></a><span class="w">  </span><span class="nt">sample_rate</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">16000</span><span class="w">           </span><span class="c1"># Microphone sample rate (Silero VAD requirement)</span>
</span><span id="__span-21-3"><a id="__codelineno-21-3" name="__codelineno-21-3" href="#__codelineno-21-3"></a><span class="w">  </span><span class="nt">channels</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span><span class="w">                  </span><span class="c1"># Mono audio</span>
</span><span id="__span-21-4"><a id="__codelineno-21-4" name="__codelineno-21-4" href="#__codelineno-21-4"></a><span class="w">  </span><span class="nt">chunk_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">512</span><span class="w">              </span><span class="c1"># Samples per chunk (Silero requirement)</span>
</span><span id="__span-21-5"><a id="__codelineno-21-5" name="__codelineno-21-5" href="#__codelineno-21-5"></a><span class="w">  </span><span class="nt">format_bits</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">16</span><span class="w">              </span><span class="c1"># int16 PCM</span>
</span><span id="__span-21-6"><a id="__codelineno-21-6" name="__codelineno-21-6" href="#__codelineno-21-6"></a>
</span><span id="__span-21-7"><a id="__codelineno-21-7" name="__codelineno-21-7" href="#__codelineno-21-7"></a><span class="w">  </span><span class="c1"># ALSA device indices (Reachy Mini)</span>
</span><span id="__span-21-8"><a id="__codelineno-21-8" name="__codelineno-21-8" href="#__codelineno-21-8"></a><span class="w">  </span><span class="nt">input_device_index</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">4</span><span class="w">        </span><span class="c1"># dsnoop (shared input)</span>
</span><span id="__span-21-9"><a id="__codelineno-21-9" name="__codelineno-21-9" href="#__codelineno-21-9"></a><span class="w">  </span><span class="nt">output_device_index</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">3</span><span class="w">       </span><span class="c1"># dmix (shared output)</span>
</span><span id="__span-21-10"><a id="__codelineno-21-10" name="__codelineno-21-10" href="#__codelineno-21-10"></a>
</span><span id="__span-21-11"><a id="__codelineno-21-11" name="__codelineno-21-11" href="#__codelineno-21-11"></a><span class="w">  </span><span class="c1"># Resilience</span>
</span><span id="__span-21-12"><a id="__codelineno-21-12" name="__codelineno-21-12" href="#__codelineno-21-12"></a><span class="w">  </span><span class="nt">max_init_retries</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">3</span><span class="w">          </span><span class="c1"># Retry audio init this many times</span>
</span><span id="__span-21-13"><a id="__codelineno-21-13" name="__codelineno-21-13" href="#__codelineno-21-13"></a><span class="w">  </span><span class="nt">retry_delay_seconds</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1.0</span><span class="w">     </span><span class="c1"># Initial delay between retries</span>
</span><span id="__span-21-14"><a id="__codelineno-21-14" name="__codelineno-21-14" href="#__codelineno-21-14"></a><span class="w">  </span><span class="nt">retry_backoff_factor</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">2.0</span><span class="w">    </span><span class="c1"># Multiply delay by this each retry</span>
</span><span id="__span-21-15"><a id="__codelineno-21-15" name="__codelineno-21-15" href="#__codelineno-21-15"></a>
</span><span id="__span-21-16"><a id="__codelineno-21-16" name="__codelineno-21-16" href="#__codelineno-21-16"></a><span class="w">  </span><span class="c1"># Buffer settings</span>
</span><span id="__span-21-17"><a id="__codelineno-21-17" name="__codelineno-21-17" href="#__codelineno-21-17"></a><span class="w">  </span><span class="nt">output_lead_in_ms</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">200</span><span class="w">       </span><span class="c1"># Silence before TTS (prevents speaker click)</span>
</span><span id="__span-21-18"><a id="__codelineno-21-18" name="__codelineno-21-18" href="#__codelineno-21-18"></a><span class="w">  </span><span class="nt">input_warmup_chunks</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">5</span><span class="w">       </span><span class="c1"># Discard first N chunks (mic settling time)</span>
</span><span id="__span-21-19"><a id="__codelineno-21-19" name="__codelineno-21-19" href="#__codelineno-21-19"></a>
</span><span id="__span-21-20"><a id="__codelineno-21-20" name="__codelineno-21-20" href="#__codelineno-21-20"></a><span class="w">  </span><span class="c1"># Health monitoring</span>
</span><span id="__span-21-21"><a id="__codelineno-21-21" name="__codelineno-21-21" href="#__codelineno-21-21"></a><span class="w">  </span><span class="nt">health_check_interval_seconds</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">5.0</span><span class="w">   </span><span class="c1"># Check stream health every N seconds</span>
</span><span id="__span-21-22"><a id="__codelineno-21-22" name="__codelineno-21-22" href="#__codelineno-21-22"></a><span class="w">  </span><span class="nt">max_consecutive_errors</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">3</span><span class="w">            </span><span class="c1"># Trigger recovery after N consecutive errors</span>
</span></code></pre></div>
<p><strong>Device index discovery</strong>:
<div class="language-bash highlight"><pre><span></span><code><span id="__span-22-1"><a id="__codelineno-22-1" name="__codelineno-22-1" href="#__codelineno-22-1"></a><span class="c1"># List audio devices</span>
</span><span id="__span-22-2"><a id="__codelineno-22-2" name="__codelineno-22-2" href="#__codelineno-22-2"></a>python<span class="w"> </span>-c<span class="w"> </span><span class="s2">&quot;import pyaudio; p = pyaudio.PyAudio(); [print(f&#39;{i}: {p.get_device_info_by_index(i)[\&quot;name\&quot;]}&#39;) for i in range(p.get_device_count())]&quot;</span>
</span></code></pre></div></p>
<h3 id="degraded-mode">Degraded Mode<a class="headerlink" href="#degraded-mode" title="Permanent link">&para;</a></h3>
<div class="language-yaml highlight"><pre><span></span><code><span id="__span-23-1"><a id="__codelineno-23-1" name="__codelineno-23-1" href="#__codelineno-23-1"></a><span class="nt">degraded_mode</span><span class="p">:</span>
</span><span id="__span-23-2"><a id="__codelineno-23-2" name="__codelineno-23-2" href="#__codelineno-23-2"></a><span class="w">  </span><span class="nt">skip_wake_word_on_failure</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span><span class="w">      </span><span class="c1"># Switch to always-listening if wake word fails</span>
</span><span id="__span-23-3"><a id="__codelineno-23-3" name="__codelineno-23-3" href="#__codelineno-23-3"></a><span class="w">  </span><span class="nt">use_energy_vad_fallback</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span><span class="w">        </span><span class="c1"># Use energy-based VAD if Silero unavailable</span>
</span><span id="__span-23-4"><a id="__codelineno-23-4" name="__codelineno-23-4" href="#__codelineno-23-4"></a><span class="w">  </span><span class="nt">log_response_on_tts_failure</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span><span class="w">    </span><span class="c1"># Log response text if TTS fails</span>
</span></code></pre></div>
<p><strong>When degraded modes activate</strong>:
- Wake word: After 3 consecutive load failures
- VAD: If Silero model fails to load (torch.hub error)
- TTS: If OpenAI connection fails and local TTS unavailable</p>
<h2 id="common-misconceptions">Common Misconceptions<a class="headerlink" href="#common-misconceptions" title="Permanent link">&para;</a></h2>
<h3 id="misconception-openai-realtime-is-just-stt-tts">Misconception: OpenAI Realtime is just STT + TTS<a class="headerlink" href="#misconception-openai-realtime-is-just-stt-tts" title="Permanent link">&para;</a></h3>
<p><strong>Reality</strong>: OpenAI Realtime is a bidirectional streaming protocol that combines:
- Speech-to-text transcription
- Text-to-speech synthesis
- Conversation session management (context, turn detection)
- Audio amplitude metadata (for visualization/animation)</p>
<p><strong>Why the confusion</strong>: Previous integrations used separate <code>/v1/audio/transcriptions</code> and <code>/v1/audio/speech</code> endpoints. Realtime unifies these into one WebSocket connection.</p>
<p><strong>Implication</strong>: Cannot mix Realtime with other TTS providers without breaking session continuity. To switch TTS providers, would need to refactor to batch mode.</p>
<hr />
<h3 id="misconception-vad-only-detects-speech-vs-silence">Misconception: VAD only detects "speech vs. silence"<a class="headerlink" href="#misconception-vad-only-detects-speech-vs-silence" title="Permanent link">&para;</a></h3>
<p><strong>Reality</strong>: Silero VAD is a PyTorch model that classifies audio as:
- <strong>Speech</strong>: Human voice (any language)
- <strong>Noise</strong>: Non-voice sounds (music, typing, background chatter)
- <strong>Silence</strong>: Near-zero amplitude</p>
<p><strong>Why the confusion</strong>: Simple energy-based VAD (amplitude threshold) only detects silence. Silero is more sophisticated—it can ignore background music while detecting overlaid speech.</p>
<p><strong>Implication</strong>: The energy fallback (<code>use_energy_vad_fallback: true</code>) is significantly less accurate in noisy environments. Silero should be preferred when available.</p>
<hr />
<h3 id="misconception-persona-switching-changes-the-ai-model">Misconception: Persona switching changes the AI model<a class="headerlink" href="#misconception-persona-switching-changes-the-ai-model" title="Permanent link">&para;</a></h3>
<p><strong>Reality</strong>: Persona switching only changes:
- OpenAI TTS voice parameter (<code>nova</code> vs. <code>onyx</code>)
- System prompt loaded into Claude Agent
- Display name shown in UI</p>
<p>The underlying models remain the same:
- STT/TTS: <code>gpt-realtime-mini</code> (OpenAI)
- Reasoning: <code>claude-sonnet-4-5</code> (Anthropic, via Agent SDK)</p>
<p><strong>Why the confusion</strong>: The term "persona" implies a different AI. In reality, it's more like "alternate personalities" of the same AI.</p>
<p><strong>Implication</strong>: Cannot have radically different capabilities per persona (e.g., one persona with tool access, another without). Capabilities are determined by the Agent's tool set, not the persona.</p>
<hr />
<h3 id="misconception-state-timeouts-are-error-conditions">Misconception: State timeouts are error conditions<a class="headerlink" href="#misconception-state-timeouts-are-error-conditions" title="Permanent link">&para;</a></h3>
<p><strong>Reality</strong>: Timeouts are <strong>safety guards</strong>, not errors. They prevent infinite loops but don't necessarily indicate a problem.</p>
<p><strong>Example</strong>: PROCESSING state has a 90-second timeout. If Claude is running a complex tool (e.g., searching emails), it might take 60 seconds—this is normal, not an error.</p>
<p><strong>Why the confusion</strong>: Timeout logs appear as errors (<code>state_timeout</code>), but they're informational.</p>
<p><strong>Implication</strong>: When debugging, check <code>duration=</code> in timeout logs. If it's close to the timeout value, the guard is working correctly. If it's significantly less, investigate why the state is hanging.</p>
<h2 id="implications-for-practice">Implications for Practice<a class="headerlink" href="#implications-for-practice" title="Permanent link">&para;</a></h2>
<h3 id="when-working-with-the-voice-pipeline">When Working with the Voice Pipeline<a class="headerlink" href="#when-working-with-the-voice-pipeline" title="Permanent link">&para;</a></h3>
<p>Understanding these concepts means:</p>
<ul>
<li>
<p><strong>State transitions are strict</strong>: Don't bypass <code>_set_state()</code>—it validates transitions, manages timeouts, and prevents race conditions. If you need a new transition, add it to <code>VALID_TRANSITIONS</code>.</p>
</li>
<li>
<p><strong>Errors are multi-level</strong>: Don't assume retry logic is sufficient. Consider degraded mode behavior for new features (e.g., if adding local TTS, define fallback when it fails).</p>
</li>
<li>
<p><strong>Audio timing is critical</strong>: The 512-sample chunk size at 16kHz is not arbitrary—it's required by Silero VAD. Changing it breaks VAD. If you need different processing windows, resample after VAD.</p>
</li>
<li>
<p><strong>Persona switches have latency</strong>: The one-turn delay is intentional. If you need instant switching, you'll need to redesign around batch STT/TTS (separate API calls per turn).</p>
</li>
<li>
<p><strong>Motion integration is bidirectional</strong>: Voice Pipeline pauses idle behavior, but motion failures can propagate back (e.g., if HeadWobble hangs, TTS might block). Always use timeouts in motion code.</p>
</li>
</ul>
<h3 id="design-patterns-that-emerge">Design Patterns That Emerge<a class="headerlink" href="#design-patterns-that-emerge" title="Permanent link">&para;</a></h3>
<p>Based on these principles, you'll often see:</p>
<p><strong>Async Context Managers for Lifecycle</strong>:
<div class="language-python highlight"><pre><span></span><code><span id="__span-24-1"><a id="__codelineno-24-1" name="__codelineno-24-1" href="#__codelineno-24-1"></a><span class="k">async</span> <span class="k">with</span> <span class="n">voice_pipeline</span><span class="o">.</span><span class="n">run</span><span class="p">():</span>
</span><span id="__span-24-2"><a id="__codelineno-24-2" name="__codelineno-24-2" href="#__codelineno-24-2"></a>    <span class="c1"># Pipeline automatically starts/stops</span>
</span><span id="__span-24-3"><a id="__codelineno-24-3" name="__codelineno-24-3" href="#__codelineno-24-3"></a>    <span class="k">await</span> <span class="n">asyncio</span><span class="o">.</span><span class="n">Event</span><span class="p">()</span><span class="o">.</span><span class="n">wait</span><span class="p">()</span>
</span></code></pre></div></p>
<p><strong>Callback Registration for Events</strong>:
<div class="language-python highlight"><pre><span></span><code><span id="__span-25-1"><a id="__codelineno-25-1" name="__codelineno-25-1" href="#__codelineno-25-1"></a><span class="n">pipeline</span><span class="o">.</span><span class="n">on_wake_word</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">model</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Detected: </span><span class="si">{</span><span class="n">model</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="__span-25-2"><a id="__codelineno-25-2" name="__codelineno-25-2" href="#__codelineno-25-2"></a><span class="n">pipeline</span><span class="o">.</span><span class="n">on_error</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">err</span><span class="p">:</span> <span class="n">log_to_sentry</span><span class="p">(</span><span class="n">err</span><span class="p">)</span>
</span></code></pre></div></p>
<p><strong>Retry with Exponential Backoff</strong>:
<div class="language-python highlight"><pre><span></span><code><span id="__span-26-1"><a id="__codelineno-26-1" name="__codelineno-26-1" href="#__codelineno-26-1"></a><span class="k">for</span> <span class="n">attempt</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_retries</span><span class="p">):</span>
</span><span id="__span-26-2"><a id="__codelineno-26-2" name="__codelineno-26-2" href="#__codelineno-26-2"></a>    <span class="k">try</span><span class="p">:</span>
</span><span id="__span-26-3"><a id="__codelineno-26-3" name="__codelineno-26-3" href="#__codelineno-26-3"></a>        <span class="k">await</span> <span class="n">connect</span><span class="p">()</span>
</span><span id="__span-26-4"><a id="__codelineno-26-4" name="__codelineno-26-4" href="#__codelineno-26-4"></a>        <span class="k">break</span>
</span><span id="__span-26-5"><a id="__codelineno-26-5" name="__codelineno-26-5" href="#__codelineno-26-5"></a>    <span class="k">except</span> <span class="ne">ConnectionError</span><span class="p">:</span>
</span><span id="__span-26-6"><a id="__codelineno-26-6" name="__codelineno-26-6" href="#__codelineno-26-6"></a>        <span class="k">await</span> <span class="n">asyncio</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="n">delay</span> <span class="o">*</span> <span class="p">(</span><span class="n">backoff</span> <span class="o">**</span> <span class="n">attempt</span><span class="p">))</span>
</span></code></pre></div></p>
<p><strong>State-Dependent Behavior</strong>:
<div class="language-python highlight"><pre><span></span><code><span id="__span-27-1"><a id="__codelineno-27-1" name="__codelineno-27-1" href="#__codelineno-27-1"></a><span class="k">if</span> <span class="n">pipeline</span><span class="o">.</span><span class="n">state</span> <span class="o">==</span> <span class="n">VoicePipelineState</span><span class="o">.</span><span class="n">LISTENING_SPEECH</span><span class="p">:</span>
</span><span id="__span-27-2"><a id="__codelineno-27-2" name="__codelineno-27-2" href="#__codelineno-27-2"></a>    <span class="c1"># Show listening indicator in UI</span>
</span><span id="__span-27-3"><a id="__codelineno-27-3" name="__codelineno-27-3" href="#__codelineno-27-3"></a><span class="k">elif</span> <span class="n">pipeline</span><span class="o">.</span><span class="n">state</span> <span class="o">==</span> <span class="n">VoicePipelineState</span><span class="o">.</span><span class="n">SPEAKING</span><span class="p">:</span>
</span><span id="__span-27-4"><a id="__codelineno-27-4" name="__codelineno-27-4" href="#__codelineno-27-4"></a>    <span class="c1"># Show speaking indicator</span>
</span></code></pre></div></p>
<h2 id="connecting-to-broader-concepts">Connecting to Broader Concepts<a class="headerlink" href="#connecting-to-broader-concepts" title="Permanent link">&para;</a></h2>
<h3 id="relationship-to-the-agent-sdk">Relationship to the Agent SDK<a class="headerlink" href="#relationship-to-the-agent-sdk" title="Permanent link">&para;</a></h3>
<p>The Voice Pipeline is a <strong>perception modality</strong> for the Claude Agent SDK. It translates audio input into text, feeds it to the agent's <code>process_input()</code> method, and renders the agent's text output as audio.</p>
<p><strong>Key insight</strong>: The agent is modality-agnostic. It receives text (from voice, chat, or webhooks) and produces text (rendered as TTS, chat messages, or API responses). The Voice Pipeline is just one adapter.</p>
<p><strong>Implications</strong>:
- Voice features (wake words, personas) don't require agent changes
- Agent improvements (better reasoning, new tools) automatically benefit voice
- Could add video input using the same pattern (vision → text → agent → TTS)</p>
<hr />
<h3 id="industry-patterns-real-time-streaming-ai">Industry Patterns: Real-Time Streaming AI<a class="headerlink" href="#industry-patterns-real-time-streaming-ai" title="Permanent link">&para;</a></h3>
<p>The Voice Pipeline follows emerging patterns in conversational AI:</p>
<p><strong>WebSocket-Based Streaming</strong>:
- Replaces traditional request/response with bidirectional streams
- Examples: OpenAI Realtime, Deepgram Streaming STT, ElevenLabs Streaming TTS
- Benefit: Lower latency (no wait for full audio before processing)</p>
<p><strong>Client-Side VAD for Turn Detection</strong>:
- Alternative to server-side VAD (e.g., GPT-4 Realtime's built-in turn detection)
- Benefit: More control over when turns end, better for multi-persona systems
- Cost: Additional CPU overhead on client</p>
<p><strong>Degraded Mode Operation</strong>:
- Inspired by "circuit breaker" pattern in microservices
- Benefit: System remains partially functional when components fail
- Example: Google Assistant falls back to cloud STT when on-device fails</p>
<hr />
<h3 id="future-directions">Future Directions<a class="headerlink" href="#future-directions" title="Permanent link">&para;</a></h3>
<p>Where this architecture might evolve:</p>
<p><strong>Local STT/TTS Models</strong>:
- On-device Whisper (STT) and Piper (TTS) for offline operation
- Challenge: Raspberry Pi 4 has limited compute for real-time inference
- Potential: Coral Edge TPU for hardware acceleration</p>
<p><strong>Multi-Modal Input</strong>:
- Add vision (camera) as input modality alongside voice
- Example: "What's in my hand?" while holding object to camera
- Requires: Multimodal agent SDK support (images → Claude)</p>
<p><strong>Conversation Memory</strong>:
- Store conversation history in semantic memory (ChromaDB)
- Enable: "What did I ask you yesterday?"
- Challenge: Privacy (requires consent), storage limits</p>
<p><strong>Emotion Detection</strong>:
- Analyze voice tone/pitch for emotional state
- Adjust persona responses based on user mood
- Example: More empathetic responses when user sounds stressed</p>
<h2 id="deep-dive-topics">Deep Dive Topics<a class="headerlink" href="#deep-dive-topics" title="Permanent link">&para;</a></h2>
<p>For those wanting even deeper understanding:</p>
<ul>
<li>
<p><strong>ALSA Architecture on Raspberry Pi</strong>: How dsnoop/dmix plugins multiplex hardware access, kernel-level audio routing, ALSA configuration files (<code>/etc/asound.conf</code>)</p>
</li>
<li>
<p><strong>Silero VAD Internals</strong>: PyTorch model architecture (LSTM + attention), training data (multilingual speech datasets), ONNX export for edge deployment</p>
</li>
<li>
<p><strong>OpenAI Realtime Protocol</strong>: WebSocket message format (JSON events), session lifecycle (session.created → input_audio_buffer.append → response.audio.delta), manual vs. server VAD modes</p>
</li>
<li>
<p><strong>State Machine Theory</strong>: Finite state machines vs. statecharts, UML state diagrams, transition validation, timeout guards as a form of timed automata</p>
</li>
</ul>
<h2 id="summary-the-mental-model">Summary: The Mental Model<a class="headerlink" href="#summary-the-mental-model" title="Permanent link">&para;</a></h2>
<p>After understanding all of this, think of the Voice Pipeline as:</p>
<p><strong>A resilient state machine that coordinates audio I/O, wake word detection, speech recognition, AI reasoning, and speech synthesis into a natural conversational flow—while gracefully degrading when components fail.</strong></p>
<p>Key insights to remember:</p>
<ol>
<li>
<p><strong>State is explicit, transitions are guarded</strong>: Every state change is validated and logged. Timeouts prevent stuck states.</p>
</li>
<li>
<p><strong>Manual VAD enables persona switching</strong>: Client-side control over audio commit timing allows changing OpenAI voice between turns.</p>
</li>
<li>
<p><strong>Motion integration is first-class</strong>: HeadWobble and idle behaviors are not afterthoughts—they're essential for natural interaction.</p>
</li>
<li>
<p><strong>Degraded modes preserve UX</strong>: When components fail, the system falls back to simpler modes (energy VAD, batch STT/TTS) rather than crashing.</p>
</li>
<li>
<p><strong>ALSA shared devices enable concurrency</strong>: dsnoop/dmix allow daemon and voice pipeline to share audio hardware without conflicts.</p>
</li>
</ol>
<h2 id="further-exploration">Further Exploration<a class="headerlink" href="#further-exploration" title="Permanent link">&para;</a></h2>
<ul>
<li><strong>To implement voice features</strong>: See <a href="../how-to/add-persona.md">How-to Guide: Adding a New Persona</a></li>
<li><strong>For API specifications</strong>: Check <a href="../reference/voice-pipeline-api.md">Voice Pipeline API Reference</a></li>
<li><strong>To understand agent integration</strong>: Read <a href="./agent-architecture.md">Agent Architecture</a></li>
<li><strong>Academic papers</strong>:</li>
<li><a href="https://arxiv.org/abs/2104.04045">Silero VAD: Lightweight Speech Detection</a></li>
<li><a href="https://platform.openai.com/docs/guides/realtime">OpenAI Realtime API Design</a></li>
<li><strong>Related projects</strong>:</li>
<li><a href="https://github.com/dscripka/openWakeWord">OpenWakeWord</a> - Custom wake word models</li>
<li><a href="https://picovoice.ai/platform/porcupine/">Porcupine</a> - Commercial wake word alternative</li>
<li><a href="https://github.com/openai/whisper">Whisper</a> - OpenAI's open-source STT model</li>
</ul>












                
              </article>
            </div>
          
          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        
<div class="md-social">
  
    
    
    
    
      
      
    
    <a href="https://github.com/jawhnycooke/claude-in-the-shell" target="_blank" rel="noopener" title="github.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      
      <script id="__config" type="application/json">{"annotate": null, "base": "../..", "features": ["navigation.instant", "navigation.tabs", "navigation.sections", "navigation.expand", "navigation.top", "search.suggest", "search.highlight", "content.code.copy", "content.tabs.link"], "search": "../../assets/javascripts/workers/search.2c215733.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../assets/javascripts/bundle.79ae519e.min.js"></script>
      
    
  </body>
</html>