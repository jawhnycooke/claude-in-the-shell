# Reachy Agent Configuration
# Copy to ~/.reachy/config.yaml and customize

version: "1.0"

agent:
  name: Jarvis
  wake_word: hey jarvis
  model: claude-haiku-4-5-20251001  # Fast model for low-latency voice
  max_tokens: 512  # Reduced for faster responses

perception:
  wake_word_engine: openwakeword
  wake_word_sensitivity: 0.5
  spatial_audio_enabled: true
  vision_enabled: true
  face_detection_enabled: true

memory:
  chroma_path: ~/.reachy/memory/chroma
  sqlite_path: ~/.reachy/memory/reachy.db
  embedding_model: all-MiniLM-L6-v2
  max_memories: 10000
  retention_days: 90

attention:
  passive_to_alert_motion_threshold: 0.3
  alert_to_passive_timeout_minutes: 5
  engaged_to_alert_silence_seconds: 30

resilience:
  thermal_threshold_celsius: 80.0
  api_timeout_seconds: 30.0
  max_retries: 3
  offline_llm_model: llama3.2:3b

privacy:
  audit_logging_enabled: true
  audit_retention_days: 7
  store_audio: false
  store_images: false

# Idle behavior - autonomous movements when not engaged
idle_behavior:
  enabled: true
  min_look_interval: 3.0      # Minimum seconds between look movements
  max_look_interval: 8.0      # Maximum seconds between look movements
  movement_duration: 1.5      # How long each look movement takes
  yaw_range: [-35, 35]        # Left/right range in degrees
  pitch_range: [-15, 20]      # Down/up range in degrees
  roll_range: [-8, 8]         # Tilt range (subtle)
  curiosity_chance: 0.15      # Probability to show curiosity emotion
  double_look_chance: 0.10    # Probability to look at same spot twice
  return_to_neutral_chance: 0.25  # Probability to return to center
  curiosity_intensity: 0.6    # Intensity of curiosity expressions
  curiosity_emotions:         # Emotions to use for curiosity
    - curious
    - thinking
    - recognition
  pause_on_interaction: true  # Pause when user is interacting
  interaction_cooldown: 2.0   # Seconds to wait after interaction ends

# Motion blending - orchestrates all motion sources
motion_blend:
  enabled: true  # Enabled - orchestrates idle behavior and wobble
  tick_rate_hz: 100.0        # Internal control loop rate
  command_rate_hz: 20.0      # Rate to send commands to daemon
  smoothing_factor: 0.3      # Pose interpolation factor (0.0-1.0)
  pose_limits:
    pitch_range: [-45, 45]   # Pitch safety limits in degrees
    yaw_range: [-45, 45]     # Yaw safety limits in degrees
    roll_range: [-30, 30]    # Roll safety limits in degrees
    z_range: [-50, 50]       # Vertical offset limits in mm
    antenna_range: [0, 90]   # Antenna position limits in degrees

# Breathing behavior - subtle idle animation (antenna oscillation)
breathing:
  enabled: false  # Disabled by preference - use idle_behavior instead
  z_amplitude_mm: 5.0        # Vertical body oscillation amplitude
  z_frequency_hz: 0.1        # 6 second breathing cycle
  antenna_amplitude_deg: 15.0  # Antenna sway amplitude
  antenna_frequency_hz: 0.5  # 2 second antenna cycle
  antenna_base_angle: 45.0   # Neutral antenna position
  pitch_amplitude_deg: 1.5   # Subtle head pitch
  pitch_frequency_hz: 0.12   # Slightly offset from Z for organic feel
  yaw_amplitude_deg: 0.8     # Very subtle yaw drift
  yaw_frequency_hz: 0.07     # Very slow drift

# Head wobble - speech-reactive animation for TTS
wobble:
  enabled: true
  max_pitch_deg: 8.0         # Maximum pitch displacement during speech
  max_yaw_deg: 6.0           # Maximum yaw displacement
  max_roll_deg: 4.0          # Maximum roll displacement
  latency_compensation_ms: 80.0  # Audio processing latency
  smoothing_factor: 0.3      # Smoothing for transitions
  noise_scale: 0.2           # Perlin-like noise overlay scale

# Voice pipeline - real-time voice interaction via OpenAI Realtime API
voice:
  enabled: false                 # Enable with --voice flag

  # Multi-persona wake word support (Ghost in the Shell theme)
  # Each persona has a distinct wake word, voice, and personality
  personas:
    hey_motoko:
      name: motoko
      display_name: Major Kusanagi
      voice: nova                # Female voice - analytical, philosophical
      prompt_path: prompts/personas/motoko.md
    hey_batou:
      name: batou
      display_name: Batou
      voice: onyx                # Male voice - casual, action-oriented
      prompt_path: prompts/personas/batou.md

  # Default persona when pipeline starts (before any wake word detected)
  default_persona: hey_motoko

  # Wake word detection
  wake_word:
    enabled: true
    model: hey_jarvis            # Fallback model if no persona models found
    sensitivity: 0.5             # 0.0 (strict) to 1.0 (lenient)
    cooldown_seconds: 2.0        # Ignore detections for this period
    custom_models_dir: data/wake_words  # Directory for custom .onnx models

  # Voice activity detection (end-of-speech)
  vad:
    silence_threshold_ms: 800    # Silence duration to trigger end-of-speech
    min_speech_duration_ms: 250  # Minimum speech to be valid
    max_speech_duration_s: 30.0  # Maximum before timeout
    speech_threshold: 0.5        # VAD sensitivity

  # OpenAI Realtime API settings
  openai:
    model: gpt-realtime-mini     # Cost-efficient, low latency
    voice: alloy                 # Options: alloy, echo, fable, onyx, nova, shimmer
    sample_rate: 24000           # OpenAI uses 24kHz
    temperature: 0.8             # Response creativity
    max_response_tokens: 4096    # Max response length
    turn_detection_threshold: 0.5
    turn_detection_silence_ms: 500

  # Audio hardware settings
  audio:
    sample_rate: 16000           # Microphone sample rate
    channels: 1                  # Mono audio
    chunk_size: 512              # Samples per chunk (Silero VAD requires 512 at 16kHz)
    format_bits: 16              # int16 PCM
    # Device indices for Reachy Mini (use shared dsnoop/dmix devices)
    # Index 4 = reachymini_audio_src (dsnoop - shared input)
    # Index 3 = reachymini_audio_sink (dmix - shared output)
    input_device_index: 4        # Use dsnoop for mic sharing with daemon
    output_device_index: 3       # Use dmix for speaker sharing with daemon

    # Resilience settings
    max_init_retries: 3          # Retry audio init this many times
    retry_delay_seconds: 1.0     # Initial delay between retries
    retry_backoff_factor: 2.0    # Multiply delay by this each retry

    # Buffer settings
    output_lead_in_ms: 200       # Silence before TTS playback (prevents click)
    input_warmup_chunks: 5       # Discard first N chunks (mic settling)

    # Health monitoring
    health_check_interval_seconds: 5.0  # Check stream health every N seconds
    max_consecutive_errors: 3    # Trigger recovery after N consecutive errors

  # Degraded mode - graceful fallback when components fail
  degraded_mode:
    skip_wake_word_on_failure: true     # Switch to always-listening if wake word fails
    use_energy_vad_fallback: true       # Use energy-based VAD if Silero unavailable
    log_response_on_tts_failure: true   # Log response text if TTS fails

  # Pipeline behavior
  confirmation_beep: true        # Play sound when wake word detected
  auto_restart: true             # Restart listening after response

# Reachy SDK - Direct Python SDK for motion control
# Uses Zenoh pub/sub (1-5ms latency) vs HTTP daemon (10-50ms)
sdk:
  enabled: true                    # Use SDK for motion control (blend controller)
  robot_name: reachy_mini          # Robot name for Zenoh connection
  connect_timeout_seconds: 10.0    # Timeout for SDK connection
  fallback_to_http: true           # Fall back to HTTP if SDK fails
  max_workers: 1                   # Thread pool size for blocking SDK calls
  localhost_only: true             # Only connect to localhost daemons

integrations:
  home_assistant:
    enabled: false
    url: null
    token_env_var: HA_TOKEN

  google_calendar:
    enabled: false
    credentials_path: null

  github:
    enabled: false
    token_env_var: GITHUB_TOKEN
    repos: []
